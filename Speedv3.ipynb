{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speedv3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkscanvas/Optimal-Satellite-Pose-Estimation-/blob/master/Speedv3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijyzTZILtffM",
        "colab_type": "text"
      },
      "source": [
        "**Mounting the Google Drive to access the dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KGc77qXZdvp",
        "colab_type": "code",
        "outputId": "581a6d86-586a-4eb0-fc24-22248db01caa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT5LcSHct93p",
        "colab_type": "text"
      },
      "source": [
        "Importing all necessary packages.\n",
        "\n",
        "\n",
        "*   The **preprocess_input** function is meant to adequate your image to the format the model requires\n",
        "*  **ImageDataGenerator:** Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXvaq5cyeZbQ",
        "colab_type": "code",
        "outputId": "2d9840b9-1a43-4528-a763-1921f435855f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "dataset_root=\"/content/gdrive/My Drive/Colab Notebooks/speed\"\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import Xception\n",
        "from keras.applications.xception import preprocess_input  \n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Flatten,BatchNormalization,Activation,AlphaDropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "  "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErLq9d5uw1po",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   **with:** there is no need to call file.close() when using with statement. The with statement itself ensures proper acquisition and release of resource, it also takes care of all the exceptions by itself\n",
        "2.   **os.path** contains functions for manipulating filenames and directory names.\n",
        "3.**os.path.join()** function will add an extra slash to the pathname before joining it to the filename.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQTpWUJ8fkim",
        "colab_type": "code",
        "outputId": "efa9f88e-5153-4eb7-9122-4e9c4be7921a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(os.path.join(dataset_root,'train.json'),'r') as train:\n",
        "  train_json=json.load(train)\n",
        "train_json[0]['q_vbs2tango']\n",
        "#len(train_json)\n",
        "type(train_json)\n",
        "# q=train_json[i]['q_vbs2tango']\n",
        "# r=train_json[i]['r_Vo2To_vbs_true']\n",
        "# a=q.extend(r)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y12IBNK5jVlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgname_list=[]\n",
        "for i in range(len(train_json)):\n",
        "  imgname_list.append(train_json[i]['filename'])\n",
        "\n",
        "#imgname_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDL69KMEzqD_",
        "colab_type": "text"
      },
      "source": [
        "Putting all the images and corresponding 7 continuous values (4 from quaternion vector, 3 from position vector) in a Pandas dataframe to be able to use with **flow_from_dataframe** function\n",
        "for multilabel regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLbgD2bUlzzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list=[]\n",
        "q1,q2,q3,q4,r1,r2,r3=[],[],[],[],[],[],[]\n",
        "for i in range(len(train_json)):\n",
        "  q1.append(train_json[i]['q_vbs2tango'][0])\n",
        "  q2.append(train_json[i]['q_vbs2tango'][1])\n",
        "  q3.append(train_json[i]['q_vbs2tango'][2])\n",
        "  q4.append(train_json[i]['q_vbs2tango'][3])\n",
        "  r1.append(train_json[i]['r_Vo2To_vbs_true'][0])\n",
        "  r2.append(train_json[i]['r_Vo2To_vbs_true'][1])\n",
        "  r3.append(train_json[i]['r_Vo2To_vbs_true'][2])\n",
        "  #q.extend(r)\n",
        "  #label_list.append(q)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sfy7lfwlMxp",
        "colab_type": "code",
        "outputId": "12edad04-4eb2-4890-94da-e7fa957ee9a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "col_dict={'image_names':imgname_list,'q1':q1,'q2':q2,'q3':q3,'q4':q4,'r1':r1,'r2':r2,'r3':r3}\n",
        "df=pd.DataFrame(col_dict)\n",
        "#df['labels']=label_list\n",
        "df_train,df_test=train_test_split(df,test_size=0.2)\n",
        "len(df_test)\n",
        "df_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_names</th>\n",
              "      <th>q1</th>\n",
              "      <th>q2</th>\n",
              "      <th>q3</th>\n",
              "      <th>q4</th>\n",
              "      <th>r1</th>\n",
              "      <th>r2</th>\n",
              "      <th>r3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9160</th>\n",
              "      <td>img011473.jpg</td>\n",
              "      <td>-0.020454</td>\n",
              "      <td>-0.602443</td>\n",
              "      <td>-0.115613</td>\n",
              "      <td>-0.789480</td>\n",
              "      <td>0.268229</td>\n",
              "      <td>0.152553</td>\n",
              "      <td>12.250661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5908</th>\n",
              "      <td>img007390.jpg</td>\n",
              "      <td>-0.705974</td>\n",
              "      <td>0.685353</td>\n",
              "      <td>0.165028</td>\n",
              "      <td>0.068248</td>\n",
              "      <td>-0.286908</td>\n",
              "      <td>0.423627</td>\n",
              "      <td>17.662971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>img000626.jpg</td>\n",
              "      <td>-0.988565</td>\n",
              "      <td>0.049722</td>\n",
              "      <td>0.029128</td>\n",
              "      <td>0.139353</td>\n",
              "      <td>0.440890</td>\n",
              "      <td>0.356666</td>\n",
              "      <td>23.841376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3037</th>\n",
              "      <td>img003816.jpg</td>\n",
              "      <td>-0.472931</td>\n",
              "      <td>0.182862</td>\n",
              "      <td>0.444381</td>\n",
              "      <td>0.738528</td>\n",
              "      <td>-0.064295</td>\n",
              "      <td>0.151893</td>\n",
              "      <td>5.067200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>img005782.jpg</td>\n",
              "      <td>0.238725</td>\n",
              "      <td>-0.540351</td>\n",
              "      <td>0.479560</td>\n",
              "      <td>-0.648886</td>\n",
              "      <td>-0.206844</td>\n",
              "      <td>-0.156809</td>\n",
              "      <td>12.987001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_names        q1        q2  ...        r1        r2         r3\n",
              "9160  img011473.jpg -0.020454 -0.602443  ...  0.268229  0.152553  12.250661\n",
              "5908  img007390.jpg -0.705974  0.685353  ... -0.286908  0.423627  17.662971\n",
              "490   img000626.jpg -0.988565  0.049722  ...  0.440890  0.356666  23.841376\n",
              "3037  img003816.jpg -0.472931  0.182862  ... -0.064295  0.151893   5.067200\n",
              "4611  img005782.jpg  0.238725 -0.540351  ... -0.206844 -0.156809  12.987001\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GqXxArr5uxZ",
        "colab_type": "text"
      },
      "source": [
        "Previously, one should have to write a custom generator if they have to perform regression or predict multiple columns and utilize the image augmentation capabilities of the ImageDataGenerator, now we can have the target values as just another column/s (must be numerical datatype) in our dataframe, simply provide the column names to the **flow_from_dataframe** and we can now use all the augmentations provided by the ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcFFc9ZwsKjT",
        "colab_type": "code",
        "outputId": "b909bae1-f1f5-4b4d-ce02-71b82117a4cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "path=\"/content/gdrive/My Drive/Colab Notebooks/speed/images/train\"\n",
        "cols=['q1','q2','q3','q4','r1','r2','r3']\n",
        "datagen=ImageDataGenerator(preprocessing_function=preprocess_input,zoom_range=0.35,brightness_range=[0.7,1.3],) #Values less than 1.0 darken the image, e.g. [0.5, 1.0], whereas values larger than 1.0 brighten the image, e.g. [1.0, 1.5], where 1.0 has no effect on brightness.\n",
        "datagen2=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "train_generator=datagen.flow_from_dataframe(df_train,directory=path,x_col='image_names',y_col=cols,class_mode='other',target_size=(299,299),batch_size=32,color_mode='rgb')\n",
        "validation_generator=datagen2.flow_from_dataframe(df_test,directory=path,x_col='image_names',y_col=cols,class_mode='other',target_size=(299,299),batch_size=32,color_mode='rgb')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"image_names\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 9599 validated image filenames.\n",
            "Found 2400 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz7seWTinME_",
        "colab_type": "code",
        "outputId": "49fc59f4-e887-4ace-feb6-2bc8f3ab4b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_generator)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U3TITUYL-GR",
        "colab_type": "text"
      },
      "source": [
        "**Building our model using Transfer Learning.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1corPUq8Aq8G",
        "colab_type": "code",
        "outputId": "df1c3ddd-06d0-4acc-9ba9-3b4fa97cc2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "\n",
        "#tensorflow.keras.backend.set_learning_phase(0)\n",
        "model_pretrained=Xception(weights='imagenet',include_top=False,input_shape=(299,299,3))\n",
        "#tensorflow.keras.backend.set_learning_phase(1)\n",
        "\n",
        "#using keras functional api to build our model\n",
        "\n",
        "x=model_pretrained.output\n",
        "\n",
        "#x=Flatten()(x)\n",
        "\n",
        "#x=Dense(32,activation='selu',kernel_initializer='lecun_normal')(x)\n",
        "        \n",
        "#x=BatchNormalization()(x)\n",
        "\n",
        "x=Dense(128,activation='relu',kernel_initializer='he_normal')(x) #\n",
        "   \n",
        "#x=AlphaDropout(0.1)(x)\n",
        "        \n",
        "# x=Dense(64,activation='selu',kernel_initializer='lecun_normal')(x) #\n",
        "   \n",
        "# x=AlphaDropout(0.1)(x)\n",
        "\n",
        "#x=BatchNormalization()(x)\n",
        "        \n",
        "#x=Dense(128,activation='selu',kernel_initializer='lecun_normal')(x)\n",
        "        \n",
        "x=Flatten()(x)\n",
        "        \n",
        "x=Dense(7,activation='linear')(x)\n",
        "\n",
        "model=Model(inputs=model_pretrained.input,outputs=x)\n",
        "\n",
        "\n",
        "# step_size_train=train_generator.n//train_generator.batch_size #It should typically be equal to the number of samples of your dataset divided by the batch size.\n",
        "# step_size_valid=validation_generator.n//validation_generator.batch_size\n",
        "# history=model.fit_generator(train_generator,steps_per_epoch=step_size_train,epochs=2,validation_data=validation_generator,validation_steps=step_size_valid)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0729 21:17:08.620064 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0729 21:17:08.667516 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0729 21:17:08.676252 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0729 21:17:08.717149 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0729 21:17:08.718073 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0729 21:17:11.777459 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0729 21:17:12.299590 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4s9o3uatNyf",
        "colab_type": "text"
      },
      "source": [
        "**IMP** Which layers to train or not should be done before model compilation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ibRWiTdunz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_generator[0][0][0][0][0]\n",
        "# train_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuJE7xvu-o-X",
        "colab_type": "code",
        "outputId": "6e058f11-28a4-4832-b284-eaff98c9e23a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i,j in enumerate(model.layers):\n",
        "  print(i,':',j)\n",
        "for layer in model.layers[:17]:\n",
        "  layer.trainable=True\n",
        "for layer in model.layers[17:]:\n",
        "  layer.trainable=True"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : <keras.engine.input_layer.InputLayer object at 0x7fe0eaf35e10>\n",
            "1 : <keras.layers.convolutional.Conv2D object at 0x7fe0eaf359e8>\n",
            "2 : <keras.layers.normalization.BatchNormalization object at 0x7fe0eaf36080>\n",
            "3 : <keras.layers.core.Activation object at 0x7fe0eaf36a58>\n",
            "4 : <keras.layers.convolutional.Conv2D object at 0x7fe0dc6ebfd0>\n",
            "5 : <keras.layers.normalization.BatchNormalization object at 0x7fe0dc70af60>\n",
            "6 : <keras.layers.core.Activation object at 0x7fe0dc67cc88>\n",
            "7 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0dc621a90>\n",
            "8 : <keras.layers.normalization.BatchNormalization object at 0x7fe0dc54e6d8>\n",
            "9 : <keras.layers.core.Activation object at 0x7fe0dc4dbd68>\n",
            "10 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0dc49f438>\n",
            "11 : <keras.layers.normalization.BatchNormalization object at 0x7fe0dc44ff98>\n",
            "12 : <keras.layers.convolutional.Conv2D object at 0x7fe0dc604f98>\n",
            "13 : <keras.layers.pooling.MaxPooling2D object at 0x7fe0dc3db7b8>\n",
            "14 : <keras.layers.normalization.BatchNormalization object at 0x7fe0dc665f60>\n",
            "15 : <keras.layers.merge.Add object at 0x7fe0dc34d6d8>\n",
            "16 : <keras.layers.core.Activation object at 0x7fe0dc286eb8>\n",
            "17 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0dc286f98>\n",
            "18 : <keras.layers.normalization.BatchNormalization object at 0x7fe0dc2326d8>\n",
            "19 : <keras.layers.core.Activation object at 0x7fe0dc178be0>\n",
            "20 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0dc1ddfd0>\n",
            "21 : <keras.layers.normalization.BatchNormalization object at 0x7fe0dc1287f0>\n",
            "22 : <keras.layers.convolutional.Conv2D object at 0x7fe0dc386320>\n",
            "23 : <keras.layers.pooling.MaxPooling2D object at 0x7fe0dc078d30>\n",
            "24 : <keras.layers.normalization.BatchNormalization object at 0x7fe0dc286240>\n",
            "25 : <keras.layers.merge.Add object at 0x7fe0dc0dee48>\n",
            "26 : <keras.layers.core.Activation object at 0x7fe0d054f780>\n",
            "27 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0d04b95c0>\n",
            "28 : <keras.layers.normalization.BatchNormalization object at 0x7fe0d0498d30>\n",
            "29 : <keras.layers.core.Activation object at 0x7fe0d04eaf98>\n",
            "30 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0d03ba6d8>\n",
            "31 : <keras.layers.normalization.BatchNormalization object at 0x7fe0d0417e48>\n",
            "32 : <keras.layers.convolutional.Conv2D object at 0x7fe0d052afd0>\n",
            "33 : <keras.layers.pooling.MaxPooling2D object at 0x7fe0d0329f98>\n",
            "34 : <keras.layers.normalization.BatchNormalization object at 0x7fe0d054f2e8>\n",
            "35 : <keras.layers.merge.Add object at 0x7fe0d034f1d0>\n",
            "36 : <keras.layers.core.Activation object at 0x7fe0d02ba7f0>\n",
            "37 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0d0303f98>\n",
            "38 : <keras.layers.normalization.BatchNormalization object at 0x7fe0d0251160>\n",
            "39 : <keras.layers.core.Activation object at 0x7fe0d01e9a20>\n",
            "40 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0d01b3f28>\n",
            "41 : <keras.layers.normalization.BatchNormalization object at 0x7fe0d019a710>\n",
            "42 : <keras.layers.core.Activation object at 0x7fe0d00e9b70>\n",
            "43 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0d01539b0>\n",
            "44 : <keras.layers.normalization.BatchNormalization object at 0x7fe0d009a748>\n",
            "45 : <keras.layers.merge.Add object at 0x7fe09144acc0>\n",
            "46 : <keras.layers.core.Activation object at 0x7fe0d025d898>\n",
            "47 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0d004cac8>\n",
            "48 : <keras.layers.normalization.BatchNormalization object at 0x7fe0913eae10>\n",
            "49 : <keras.layers.core.Activation object at 0x7fe0913b0be0>\n",
            "50 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe091337470>\n",
            "51 : <keras.layers.normalization.BatchNormalization object at 0x7fe091315ef0>\n",
            "52 : <keras.layers.core.Activation object at 0x7fe0912a4da0>\n",
            "53 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0912355c0>\n",
            "54 : <keras.layers.normalization.BatchNormalization object at 0x7fe091211d30>\n",
            "55 : <keras.layers.merge.Add object at 0x7fe0911a4e80>\n",
            "56 : <keras.layers.core.Activation object at 0x7fe0d004cdd8>\n",
            "57 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe091168a20>\n",
            "58 : <keras.layers.normalization.BatchNormalization object at 0x7fe0910d76d8>\n",
            "59 : <keras.layers.core.Activation object at 0x7fe0910a6eb8>\n",
            "60 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0910685c0>\n",
            "61 : <keras.layers.normalization.BatchNormalization object at 0x7fe091017f60>\n",
            "62 : <keras.layers.core.Activation object at 0x7fe090fa4860>\n",
            "63 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe090f696d8>\n",
            "64 : <keras.layers.normalization.BatchNormalization object at 0x7fe090f15f28>\n",
            "65 : <keras.layers.merge.Add object at 0x7fe090ea69e8>\n",
            "66 : <keras.layers.core.Activation object at 0x7fe0911680b8>\n",
            "67 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe090e50668>\n",
            "68 : <keras.layers.normalization.BatchNormalization object at 0x7fe090dd6198>\n",
            "69 : <keras.layers.core.Activation object at 0x7fe090d6db38>\n",
            "70 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe090d51fd0>\n",
            "71 : <keras.layers.normalization.BatchNormalization object at 0x7fe090d1b780>\n",
            "72 : <keras.layers.core.Activation object at 0x7fe090c68c88>\n",
            "73 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe090c4fb38>\n",
            "74 : <keras.layers.normalization.BatchNormalization object at 0x7fe090b87e10>\n",
            "75 : <keras.layers.merge.Add object at 0x7fe090b51c18>\n",
            "76 : <keras.layers.core.Activation object at 0x7fe090e50978>\n",
            "77 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe090b51b00>\n",
            "78 : <keras.layers.normalization.BatchNormalization object at 0x7fe090af4240>\n",
            "79 : <keras.layers.core.Activation object at 0x7fe090a50cc0>\n",
            "80 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0909d3588>\n",
            "81 : <keras.layers.normalization.BatchNormalization object at 0x7fe090a33cf8>\n",
            "82 : <keras.layers.core.Activation object at 0x7fe090944e80>\n",
            "83 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0908d76d8>\n",
            "84 : <keras.layers.normalization.BatchNormalization object at 0x7fe090938e48>\n",
            "85 : <keras.layers.merge.Add object at 0x7fe090844fd0>\n",
            "86 : <keras.layers.core.Activation object at 0x7fe090b6beb8>\n",
            "87 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe09086c1d0>\n",
            "88 : <keras.layers.normalization.BatchNormalization object at 0x7fe0907f6940>\n",
            "89 : <keras.layers.core.Activation object at 0x7fe090745c18>\n",
            "90 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe090707710>\n",
            "91 : <keras.layers.normalization.BatchNormalization object at 0x7fe090735f28>\n",
            "92 : <keras.layers.core.Activation object at 0x7fe0906429e8>\n",
            "93 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe090607860>\n",
            "94 : <keras.layers.normalization.BatchNormalization object at 0x7fe090638550>\n",
            "95 : <keras.layers.merge.Add object at 0x7fe090547b38>\n",
            "96 : <keras.layers.core.Activation object at 0x7fe09086c518>\n",
            "97 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0905395c0>\n",
            "98 : <keras.layers.normalization.BatchNormalization object at 0x7fe0904f9ef0>\n",
            "99 : <keras.layers.core.Activation object at 0x7fe0904728d0>\n",
            "100 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe09040c6a0>\n",
            "101 : <keras.layers.normalization.BatchNormalization object at 0x7fe0903a6e10>\n",
            "102 : <keras.layers.core.Activation object at 0x7fe09036ec18>\n",
            "103 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe09036ef28>\n",
            "104 : <keras.layers.normalization.BatchNormalization object at 0x7fe0902f72b0>\n",
            "105 : <keras.layers.merge.Add object at 0x7fe09026ed68>\n",
            "106 : <keras.layers.core.Activation object at 0x7fe09056fac8>\n",
            "107 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe090196240>\n",
            "108 : <keras.layers.normalization.BatchNormalization object at 0x7fe09020cf98>\n",
            "109 : <keras.layers.core.Activation object at 0x7fe090170cf8>\n",
            "110 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe0900f6710>\n",
            "111 : <keras.layers.normalization.BatchNormalization object at 0x7fe0900d2dd8>\n",
            "112 : <keras.layers.core.Activation object at 0x7fe09005ffd0>\n",
            "113 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe087fec400>\n",
            "114 : <keras.layers.normalization.BatchNormalization object at 0x7fe087f9eef0>\n",
            "115 : <keras.layers.merge.Add object at 0x7fe087f26fd0>\n",
            "116 : <keras.layers.core.Activation object at 0x7fe087e156a0>\n",
            "117 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe087deecc0>\n",
            "118 : <keras.layers.normalization.BatchNormalization object at 0x7fe087d85ef0>\n",
            "119 : <keras.layers.core.Activation object at 0x7fe087cd4fd0>\n",
            "120 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe087d3aa20>\n",
            "121 : <keras.layers.normalization.BatchNormalization object at 0x7fe087c40240>\n",
            "122 : <keras.layers.convolutional.Conv2D object at 0x7fe087ebee80>\n",
            "123 : <keras.layers.pooling.MaxPooling2D object at 0x7fe087c3ad30>\n",
            "124 : <keras.layers.normalization.BatchNormalization object at 0x7fe087e29828>\n",
            "125 : <keras.layers.merge.Add object at 0x7fe087bd3ef0>\n",
            "126 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe087b5f4a8>\n",
            "127 : <keras.layers.normalization.BatchNormalization object at 0x7fe087ad87b8>\n",
            "128 : <keras.layers.core.Activation object at 0x7fe087aefa20>\n",
            "129 : <keras.layers.convolutional.SeparableConv2D object at 0x7fe087abaf28>\n",
            "130 : <keras.layers.normalization.BatchNormalization object at 0x7fe087a9e710>\n",
            "131 : <keras.layers.core.Activation object at 0x7fe0879c7fd0>\n",
            "132 : <keras.layers.core.Dense object at 0x7fe0901c1f28>\n",
            "133 : <keras.layers.core.Flatten object at 0x7fe0eaf35710>\n",
            "134 : <keras.layers.core.Dense object at 0x7fe086e06128>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOnecUjTQuCG",
        "colab_type": "code",
        "outputId": "9d5b3c73-1524-4f37-ab28-cc90d4a3623f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 74, 74, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 37, 37, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 19, 19, 728)  2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10, 10, 128)  262272      block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 12800)        0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 7)            89607       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 21,213,359\n",
            "Trainable params: 21,158,831\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ52TuABAa8v",
        "colab_type": "code",
        "outputId": "7114749b-840b-4d27-83e3-cf1d8a92a208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "sgd=keras.optimizers.sgd(lr=1e-4,decay=5e-4, momentum=0.9, nesterov=True)\n",
        "adam=keras.optimizers.adam(lr=1e-3)\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=5, min_lr=1e-20,mode='min',verbose=1)\n",
        "early_stopping=keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,verbose=1,mode='min',min_delta=0.01,restore_best_weights=True)\n",
        "model.compile(optimizer=sgd,loss='mean_squared_error') #,metrics=['mse']\n",
        "step_size_train=train_generator.n//train_generator.batch_size #It should typically be equal to the number of samples of your dataset divided by the batch size.\n",
        "step_size_valid=validation_generator.n//validation_generator.batch_size\n",
        "history=model.fit_generator(train_generator,steps_per_epoch=step_size_train,epochs=50,validation_data=validation_generator,validation_steps=step_size_valid,callbacks=[reduce_lr]) #,early_stopping\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0729 21:17:20.794524 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "299/299 [==============================] - 4915s 16s/step - loss: 2.6545 - val_loss: 1.3412\n",
            "Epoch 2/50\n",
            "299/299 [==============================] - 514s 2s/step - loss: 1.3762 - val_loss: 1.1250\n",
            "Epoch 3/50\n",
            "299/299 [==============================] - 502s 2s/step - loss: 1.1811 - val_loss: 0.9668\n",
            "Epoch 4/50\n",
            "299/299 [==============================] - 515s 2s/step - loss: 1.0667 - val_loss: 0.8476\n",
            "Epoch 5/50\n",
            "299/299 [==============================] - 522s 2s/step - loss: 0.9643 - val_loss: 0.8240\n",
            "Epoch 6/50\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.9086 - val_loss: 0.8387\n",
            "Epoch 7/50\n",
            "299/299 [==============================] - 516s 2s/step - loss: 0.8161 - val_loss: 0.7444\n",
            "Epoch 8/50\n",
            "273/299 [==========================>...] - ETA: 40s - loss: 0.7975"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0729 21:17:20.794524 140605397030784 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "299/299 [==============================] - 4915s 16s/step - loss: 2.6545 - val_loss: 1.3412\n",
            "Epoch 2/50\n",
            "299/299 [==============================] - 514s 2s/step - loss: 1.3762 - val_loss: 1.1250\n",
            "Epoch 3/50\n",
            "299/299 [==============================] - 502s 2s/step - loss: 1.1811 - val_loss: 0.9668\n",
            "Epoch 4/50\n",
            "299/299 [==============================] - 515s 2s/step - loss: 1.0667 - val_loss: 0.8476\n",
            "Epoch 5/50\n",
            "299/299 [==============================] - 522s 2s/step - loss: 0.9643 - val_loss: 0.8240\n",
            "Epoch 6/50\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.9086 - val_loss: 0.8387\n",
            "Epoch 7/50\n",
            "299/299 [==============================] - 516s 2s/step - loss: 0.8161 - val_loss: 0.7444\n",
            "Epoch 8/50\n",
            "299/299 [==============================] - 516s 2s/step - loss: 0.7907 - val_loss: 0.6897\n",
            "299/299 [==============================] - 516s 2s/step - loss: 0.7907 - val_loss: 0.6897\n",
            "Epoch 9/50\n",
            "Epoch 9/50\n",
            "299/299 [==============================] - 513s 2s/step - loss: 0.8025 - val_loss: 0.6871\n",
            "299/299 [==============================] - 513s 2s/step - loss: 0.8025 - val_loss: 0.6871\n",
            "Epoch 10/50\n",
            "Epoch 10/50\n",
            "299/299 [==============================] - 514s 2s/step - loss: 0.7768 - val_loss: 0.7491\n",
            "299/299 [==============================] - 514s 2s/step - loss: 0.7768 - val_loss: 0.7491\n",
            "Epoch 11/50\n",
            "Epoch 11/50\n",
            "299/299 [==============================] - 518s 2s/step - loss: 0.7237 - val_loss: 0.6607\n",
            "299/299 [==============================] - 518s 2s/step - loss: 0.7237 - val_loss: 0.6607\n",
            "Epoch 12/50\n",
            "Epoch 12/50\n",
            "299/299 [==============================] - 520s 2s/step - loss: 0.7086 - val_loss: 0.7264\n",
            "299/299 [==============================] - 520s 2s/step - loss: 0.7086 - val_loss: 0.7264\n",
            "Epoch 13/50\n",
            "Epoch 13/50\n",
            "299/299 [==============================] - 524s 2s/step - loss: 0.6727 - val_loss: 0.6897\n",
            "299/299 [==============================] - 524s 2s/step - loss: 0.6727 - val_loss: 0.6897\n",
            "Epoch 14/50\n",
            "Epoch 14/50\n",
            "299/299 [==============================] - 524s 2s/step - loss: 0.6638 - val_loss: 0.6352\n",
            "299/299 [==============================] - 524s 2s/step - loss: 0.6638 - val_loss: 0.6352\n",
            "Epoch 15/50\n",
            "Epoch 15/50\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.6484 - val_loss: 0.6552\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.6484 - val_loss: 0.6552\n",
            "Epoch 16/50\n",
            "Epoch 16/50\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.6408 - val_loss: 0.7124\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.6408 - val_loss: 0.7124\n",
            "Epoch 17/50\n",
            "Epoch 17/50\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.6332 - val_loss: 0.6478\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.6332 - val_loss: 0.6478\n",
            "Epoch 18/50\n",
            "Epoch 18/50\n",
            "299/299 [==============================] - 520s 2s/step - loss: 0.6335 - val_loss: 0.6421\n",
            "299/299 [==============================] - 520s 2s/step - loss: 0.6335 - val_loss: 0.6421\n",
            "Epoch 19/50\n",
            "Epoch 19/50\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.6073 - val_loss: 0.6977\n",
            "299/299 [==============================] - 523s 2s/step - loss: 0.6073 - val_loss: 0.6977\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 20/50\n",
            "299/299 [==============================] - 518s 2s/step - loss: 0.5842 - val_loss: 0.6594\n",
            "299/299 [==============================] - 518s 2s/step - loss: 0.5842 - val_loss: 0.6594\n",
            "Epoch 21/50\n",
            "Epoch 21/50\n",
            "299/299 [==============================] - 521s 2s/step - loss: 0.5913 - val_loss: 0.6425\n",
            "299/299 [==============================] - 521s 2s/step - loss: 0.5913 - val_loss: 0.6425\n",
            "Epoch 22/50\n",
            "Epoch 22/50\n",
            "299/299 [==============================] - 519s 2s/step - loss: 0.5906 - val_loss: 0.6547\n",
            "299/299 [==============================] - 519s 2s/step - loss: 0.5906 - val_loss: 0.6547\n",
            "Epoch 23/50\n",
            "Epoch 23/50\n",
            "299/299 [==============================] - 515s 2s/step - loss: 0.5773 - val_loss: 0.6547\n",
            "299/299 [==============================] - 515s 2s/step - loss: 0.5773 - val_loss: 0.6547\n",
            "Epoch 24/50\n",
            "Epoch 24/50\n",
            "299/299 [==============================] - 519s 2s/step - loss: 0.5712 - val_loss: 0.6444\n",
            "299/299 [==============================] - 519s 2s/step - loss: 0.5712 - val_loss: 0.6444\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 25/50\n",
            "299/299 [==============================] - 518s 2s/step - loss: 0.5771 - val_loss: 0.6444\n",
            "299/299 [==============================] - 518s 2s/step - loss: 0.5771 - val_loss: 0.6444\n",
            "Epoch 26/50\n",
            "Epoch 26/50\n",
            "299/299 [==============================] - 515s 2s/step - loss: 0.5786 - val_loss: 0.6395\n",
            "299/299 [==============================] - 515s 2s/step - loss: 0.5786 - val_loss: 0.6395\n",
            "Epoch 27/50\n",
            "Epoch 27/50\n",
            "299/299 [==============================] - 516s 2s/step - loss: 0.5909 - val_loss: 0.6581\n",
            "299/299 [==============================] - 516s 2s/step - loss: 0.5909 - val_loss: 0.6581\n",
            "Epoch 28/50\n",
            "Epoch 28/50\n",
            "299/299 [==============================] - 501s 2s/step - loss: 0.5846 - val_loss: 0.6563\n",
            "299/299 [==============================] - 501s 2s/step - loss: 0.5846 - val_loss: 0.6563\n",
            "Epoch 29/50\n",
            "Epoch 29/50\n",
            "299/299 [==============================] - 490s 2s/step - loss: 0.5807 - val_loss: 0.6680\n",
            "299/299 [==============================] - 490s 2s/step - loss: 0.5807 - val_loss: 0.6680\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 30/50\n",
            "299/299 [==============================] - 484s 2s/step - loss: 0.5692 - val_loss: 0.6530\n",
            "299/299 [==============================] - 484s 2s/step - loss: 0.5692 - val_loss: 0.6530\n",
            "Epoch 31/50\n",
            "Epoch 31/50\n",
            "299/299 [==============================] - 483s 2s/step - loss: 0.5785 - val_loss: 0.6557\n",
            "299/299 [==============================] - 483s 2s/step - loss: 0.5785 - val_loss: 0.6557\n",
            "Epoch 32/50\n",
            "Epoch 32/50\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5686 - val_loss: 0.6568\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5686 - val_loss: 0.6568\n",
            "Epoch 33/50\n",
            "Epoch 33/50\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5786 - val_loss: 0.6626\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5786 - val_loss: 0.6626\n",
            "Epoch 34/50\n",
            "Epoch 34/50\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5869 - val_loss: 0.6620\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5869 - val_loss: 0.6620\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 35/50\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5802 - val_loss: 0.6566\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5802 - val_loss: 0.6566\n",
            "Epoch 36/50\n",
            "Epoch 36/50\n",
            "299/299 [==============================] - 483s 2s/step - loss: 0.5506 - val_loss: 0.6491\n",
            "299/299 [==============================] - 483s 2s/step - loss: 0.5506 - val_loss: 0.6491\n",
            "Epoch 37/50\n",
            "Epoch 37/50\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5904 - val_loss: 0.6627\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5904 - val_loss: 0.6627\n",
            "Epoch 38/50\n",
            "Epoch 38/50\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5902 - val_loss: 0.6583\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5902 - val_loss: 0.6583\n",
            "Epoch 39/50\n",
            "Epoch 39/50\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5772 - val_loss: 0.6675\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5772 - val_loss: 0.6675\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 40/50\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5708 - val_loss: 0.6565\n",
            "299/299 [==============================] - 482s 2s/step - loss: 0.5708 - val_loss: 0.6565\n",
            "Epoch 41/50\n",
            "Epoch 41/50\n",
            "299/299 [==============================] - 490s 2s/step - loss: 0.5707 - val_loss: 0.6645\n",
            "299/299 [==============================] - 490s 2s/step - loss: 0.5707 - val_loss: 0.6645\n",
            "Epoch 42/50\n",
            "Epoch 42/50\n",
            "299/299 [==============================] - 500s 2s/step - loss: 0.5659 - val_loss: 0.6557\n",
            "299/299 [==============================] - 500s 2s/step - loss: 0.5659 - val_loss: 0.6557\n",
            "Epoch 43/50\n",
            "Epoch 43/50\n",
            "299/299 [==============================] - 508s 2s/step - loss: 0.5798 - val_loss: 0.6469\n",
            "299/299 [==============================] - 508s 2s/step - loss: 0.5798 - val_loss: 0.6469\n",
            "Epoch 44/50\n",
            "Epoch 44/50\n",
            "299/299 [==============================] - 505s 2s/step - loss: 0.5736 - val_loss: 0.6635\n",
            "299/299 [==============================] - 505s 2s/step - loss: 0.5736 - val_loss: 0.6635\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
            "Epoch 45/50\n",
            "299/299 [==============================] - 508s 2s/step - loss: 0.5799 - val_loss: 0.6533\n",
            "299/299 [==============================] - 508s 2s/step - loss: 0.5799 - val_loss: 0.6533\n",
            "Epoch 46/50\n",
            "Epoch 46/50\n",
            "299/299 [==============================] - 505s 2s/step - loss: 0.5639 - val_loss: 0.6523\n",
            "299/299 [==============================] - 505s 2s/step - loss: 0.5639 - val_loss: 0.6523\n",
            "Epoch 47/50\n",
            "Epoch 47/50\n",
            "299/299 [==============================] - 518s 2s/step - loss: 0.6049 - val_loss: 0.6528\n",
            "299/299 [==============================] - 518s 2s/step - loss: 0.6049 - val_loss: 0.6528\n",
            "Epoch 48/50\n",
            "Epoch 48/50\n",
            "299/299 [==============================] - 512s 2s/step - loss: 0.5709 - val_loss: 0.6600\n",
            "299/299 [==============================] - 512s 2s/step - loss: 0.5709 - val_loss: 0.6600\n",
            "Epoch 49/50\n",
            "Epoch 49/50\n",
            "299/299 [==============================] - 513s 2s/step - loss: 0.5970 - val_loss: 0.6587\n",
            "299/299 [==============================] - 513s 2s/step - loss: 0.5970 - val_loss: 0.6587\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
            "Epoch 50/50\n",
            "299/299 [==============================] - 524s 2s/step - loss: 0.5717 - val_loss: 0.6597\n",
            "299/299 [==============================] - 524s 2s/step - loss: 0.5717 - val_loss: 0.6597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz2FLxagH-Y3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fa228b54-a952-4b94-878c-364d8b057bbd"
      },
      "source": [
        "\n",
        "for e,v in enumerate(history.history['val_loss']):\n",
        "  print(\"Epoch \",e,\":\",v)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 : 1.3412485615412395\n",
            "Epoch  1 : 1.1250213158130646\n",
            "Epoch  2 : 0.9667775269349416\n",
            "Epoch  3 : 0.8475951560338338\n",
            "Epoch  4 : 0.824042368332545\n",
            "Epoch  5 : 0.8386900130907694\n",
            "Epoch  6 : 0.7444442554314932\n",
            "Epoch  7 : 0.6896725352605184\n",
            "Epoch  8 : 0.6870649929841359\n",
            "Epoch  9 : 0.7491014301776886\n",
            "Epoch  10 : 0.6607096286614736\n",
            "Epoch  11 : 0.7263505224386851\n",
            "Epoch  12 : 0.6897197731335958\n",
            "Epoch  13 : 0.6351891096433003\n",
            "Epoch  14 : 0.6551571647326152\n",
            "Epoch  15 : 0.7123882369200388\n",
            "Epoch  16 : 0.6477623959382375\n",
            "Epoch  17 : 0.6421271824836731\n",
            "Epoch  18 : 0.697657295068105\n",
            "Epoch  19 : 0.6593638598918915\n",
            "Epoch  20 : 0.6425310707092285\n",
            "Epoch  21 : 0.654748817284902\n",
            "Epoch  22 : 0.6547492706775665\n",
            "Epoch  23 : 0.6443561808268229\n",
            "Epoch  24 : 0.6444401999314626\n",
            "Epoch  25 : 0.6395418024063111\n",
            "Epoch  26 : 0.6580760717391968\n",
            "Epoch  27 : 0.6562818372249604\n",
            "Epoch  28 : 0.6680225217342377\n",
            "Epoch  29 : 0.653035862048467\n",
            "Epoch  30 : 0.6556802419821421\n",
            "Epoch  31 : 0.6567828210194906\n",
            "Epoch  32 : 0.66260107477506\n",
            "Epoch  33 : 0.6620470305283864\n",
            "Epoch  34 : 0.6566265066464742\n",
            "Epoch  35 : 0.6491010451316833\n",
            "Epoch  36 : 0.6627299412091573\n",
            "Epoch  37 : 0.6583103787899017\n",
            "Epoch  38 : 0.6674626306692759\n",
            "Epoch  39 : 0.6564921299616496\n",
            "Epoch  40 : 0.6644569849967956\n",
            "Epoch  41 : 0.6556657739480336\n",
            "Epoch  42 : 0.6469398001829784\n",
            "Epoch  43 : 0.6635055931409201\n",
            "Epoch  44 : 0.6532709844907125\n",
            "Epoch  45 : 0.6523267976442972\n",
            "Epoch  46 : 0.6527636575698853\n",
            "Epoch  47 : 0.6599605985482534\n",
            "Epoch  48 : 0.6587214310963948\n",
            "Epoch  49 : 0.6597454396883646\n",
            "Epoch  0 : 1.3412485615412395\n",
            "Epoch  1 : 1.1250213158130646\n",
            "Epoch  2 : 0.9667775269349416\n",
            "Epoch  3 : 0.8475951560338338\n",
            "Epoch  4 : 0.824042368332545\n",
            "Epoch  5 : 0.8386900130907694\n",
            "Epoch  6 : 0.7444442554314932\n",
            "Epoch  7 : 0.6896725352605184\n",
            "Epoch  8 : 0.6870649929841359\n",
            "Epoch  9 : 0.7491014301776886\n",
            "Epoch  10 : 0.6607096286614736\n",
            "Epoch  11 : 0.7263505224386851\n",
            "Epoch  12 : 0.6897197731335958\n",
            "Epoch  13 : 0.6351891096433003\n",
            "Epoch  14 : 0.6551571647326152\n",
            "Epoch  15 : 0.7123882369200388\n",
            "Epoch  16 : 0.6477623959382375\n",
            "Epoch  17 : 0.6421271824836731\n",
            "Epoch  18 : 0.697657295068105\n",
            "Epoch  19 : 0.6593638598918915\n",
            "Epoch  20 : 0.6425310707092285\n",
            "Epoch  21 : 0.654748817284902\n",
            "Epoch  22 : 0.6547492706775665\n",
            "Epoch  23 : 0.6443561808268229\n",
            "Epoch  24 : 0.6444401999314626\n",
            "Epoch  25 : 0.6395418024063111\n",
            "Epoch  26 : 0.6580760717391968\n",
            "Epoch  27 : 0.6562818372249604\n",
            "Epoch  28 : 0.6680225217342377\n",
            "Epoch  29 : 0.653035862048467\n",
            "Epoch  30 : 0.6556802419821421\n",
            "Epoch  31 : 0.6567828210194906\n",
            "Epoch  32 : 0.66260107477506\n",
            "Epoch  33 : 0.6620470305283864\n",
            "Epoch  34 : 0.6566265066464742\n",
            "Epoch  35 : 0.6491010451316833\n",
            "Epoch  36 : 0.6627299412091573\n",
            "Epoch  37 : 0.6583103787899017\n",
            "Epoch  38 : 0.6674626306692759\n",
            "Epoch  39 : 0.6564921299616496\n",
            "Epoch  40 : 0.6644569849967956\n",
            "Epoch  41 : 0.6556657739480336\n",
            "Epoch  42 : 0.6469398001829784\n",
            "Epoch  43 : 0.6635055931409201\n",
            "Epoch  44 : 0.6532709844907125\n",
            "Epoch  45 : 0.6523267976442972\n",
            "Epoch  46 : 0.6527636575698853\n",
            "Epoch  47 : 0.6599605985482534\n",
            "Epoch  48 : 0.6587214310963948\n",
            "Epoch  49 : 0.6597454396883646\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWp83iCg6ZnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "c69e24c7-9c20-4b81-a399-8a551e452db7"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq0KUOO68Zhe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "f13d152e-f853-4e35-eb3b-e4993b5b7e83"
      },
      "source": [
        "#Evaluating the model\n",
        "test_result=[]\n",
        "q_est,r_est=[],[]\n",
        "with open(os.path.join(dataset_root,'real.json'),'r') as f_eval:\n",
        "  test_list=json.load(f_eval)\n",
        "\n",
        "for img in test_list:\n",
        "  img_path=os.path.join(dataset_root,'images','real',img['filename'])\n",
        "  img_arr=image.load_img(img_path,target_size=(299,299))\n",
        "  x=image.img_to_array(img_arr)\n",
        "  x=preprocess_input(x)\n",
        "  x=np.expand_dims(x,axis=0)\n",
        "  output=model.predict(x)\n",
        "  output=output.tolist()\n",
        "  test_result.append({'filename':img['filename'],'q':output[:4],'r':output[4:]})\n",
        "  q_est.append(output[0][:4])\n",
        "  r_est.append(output[0][4:])\n",
        "  print(output)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.08568225800991058, 0.07686755061149597, 0.036857474595308304, -0.055088624358177185, 0.062264181673526764, 0.053731370717287064, 3.036977529525757]]\n",
            "[[0.08568225800991058, 0.07686755061149597, 0.036857474595308304, -0.055088624358177185, 0.062264181673526764, 0.053731370717287064, 3.036977529525757]]\n",
            "[[-0.2942650318145752, 0.10394446551799774, -0.04405135288834572, -0.09130121022462845, 0.03899755701422691, -0.15071018040180206, 3.413869857788086]]\n",
            "[[-0.2942650318145752, 0.10394446551799774, -0.04405135288834572, -0.09130121022462845, 0.03899755701422691, -0.15071018040180206, 3.413869857788086]]\n",
            "[[0.08134737610816956, 0.04018733277916908, -0.088424913585186, -0.08146484196186066, -0.4453805088996887, -0.24598000943660736, 4.721578598022461]]\n",
            "[[0.08134737610816956, 0.04018733277916908, -0.088424913585186, -0.08146484196186066, -0.4453805088996887, -0.24598000943660736, 4.721578598022461]]\n",
            "[[0.040433090180158615, -0.012583189643919468, -0.10285767912864685, -0.08099297434091568, 0.06603842228651047, -0.011745543219149113, 3.7694127559661865]]\n",
            "[[0.040433090180158615, -0.012583189643919468, -0.10285767912864685, -0.08099297434091568, 0.06603842228651047, -0.011745543219149113, 3.7694127559661865]]\n",
            "[[0.09431596845388412, 0.0004463947843760252, -0.031171830371022224, -0.131365567445755, -0.16320998966693878, -0.13603150844573975, 3.8056914806365967]]\n",
            "[[0.09431596845388412, 0.0004463947843760252, -0.031171830371022224, -0.131365567445755, -0.16320998966693878, -0.13603150844573975, 3.8056914806365967]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIiK4fcvBPr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img_path=os.path.join(dataset_root,'images','test','img000014.jpg')\n",
        "# img_arr=image.load_img(img_path,target_size=(299,299))\n",
        "# x=image.img_to_array(img_arr)\n",
        "# x=preprocess_input(x)\n",
        "# x=np.expand_dims(x,axis=0)\n",
        "# output=model.predict(x)\n",
        "# output=output.tolist()\n",
        "# output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIM3gs2Sn4Zo",
        "colab_type": "text"
      },
      "source": [
        "**Extracting r_gt and q_gt from real.json**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ojs_fgUl6cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_json=[]\n",
        "q_gt,r_gt=[],[]\n",
        "with open(os.path.join(dataset_root,'real.json'),'r') as f:\n",
        "  real_json=json.load(f)\n",
        "for i in range(len(real_json)):\n",
        "  q_gt.append(real_json[i]['q_vbs2tango'])\n",
        "  r_gt.append(real_json[i]['r_Vo2To_vbs_true'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwJQ8wnhv-y-",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Orientation Score.**\n",
        "\n",
        "Orientation score is the angle of the rotation, that aligns the estimated and ground truth orientations:\n",
        "\n",
        "score(i)orientation=2⋅arccos(∣∣⟨q(i)est,q(i)gt⟩∣∣)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMhDPt4loE0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58046e81-241b-4ba8-d2da-0f7a971abc03"
      },
      "source": [
        "import math\n",
        "score_orientation=0\n",
        "bra_ket=[]\n",
        "for i in range(len(real_json)):\n",
        "  bra_ket.append(q_est[i][0]*q_gt[i][0]+q_est[i][1]*q_gt[i][1]+q_est[i][2]*q_gt[i][2]+q_est[i][3]*q_gt[i][3])\n",
        "  \n",
        "  \n",
        "for i in range(len(real_json)):\n",
        "  if bra_ket[i]<1:\n",
        "    score_orientation+=2*math.acos(bra_ket[i])\n",
        "score_orientation\n",
        "#bra_ket\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.957223481712035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.957223481712035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1nAYXDswRCT",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Position Score**\n",
        "\n",
        "The position score for image i is simply the 2-norm of the position error (difference of estimated and ground truth position vectors), normalized with the ground truth distance of the satellite:\n",
        "\n",
        "score(i)position=∣∣r(i)gt−r(i)est∣∣2∣∣r(i)gt∣∣2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVgBqFY6wbRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c224c43-e6f4-4a52-dd8a-fc498031eaef"
      },
      "source": [
        "from numpy import linalg\n",
        "score_position=0\n",
        "for i in range(len(real_json)):\n",
        "   score_position+=(abs(linalg.norm([r_gt[i]],2)-linalg.norm([r_est[i]],2))/linalg.norm([r_gt[i]],2))\n",
        "\n",
        "#linalg.norm([r_gt[0]])\n",
        "score_position"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3112730431290028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3112730431290028"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZO0fome1Hil",
        "colab_type": "text"
      },
      "source": [
        "**Finally, the total score is the average of pose scores over all images of the test set:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Yo9gyh1JD6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0efee82e-3b1d-408a-f47e-83dc4a9c0ea7"
      },
      "source": [
        "score=(score_orientation+score_position)/len(real_json)\n",
        "score"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0536993049682075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0536993049682075"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}