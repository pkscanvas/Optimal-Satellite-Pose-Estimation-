{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Speedv2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkscanvas/Optimal-Satellite-Pose-Estimation-/blob/master/Copy_of_Speedv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijyzTZILtffM",
        "colab_type": "text"
      },
      "source": [
        "**Mounting the Google Drive to access the dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KGc77qXZdvp",
        "colab_type": "code",
        "outputId": "20bfb4bc-747a-4375-d69c-c4b8764980c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT5LcSHct93p",
        "colab_type": "text"
      },
      "source": [
        "Importing all necessary packages.\n",
        "\n",
        "\n",
        "*   The **preprocess_input** function is meant to adequate your image to the format the model requires\n",
        "*  **ImageDataGenerator:** Generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXvaq5cyeZbQ",
        "colab_type": "code",
        "outputId": "0ad9f659-0fa6-4f21-f02a-444aef9a5033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "dataset_root=\"/content/gdrive/My Drive/Colab Notebooks/speed\"\n",
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import keras\n",
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import Xception\n",
        "from keras.applications.xception import preprocess_input  \n",
        "from keras.models import Model\n",
        "from keras.layers import Dense,Flatten,BatchNormalization,Activation,AlphaDropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErLq9d5uw1po",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   **with:** there is no need to call file.close() when using with statement. The with statement itself ensures proper acquisition and release of resource, it also takes care of all the exceptions by itself\n",
        "2.   **os.path** contains functions for manipulating filenames and directory names.\n",
        "3.**os.path.join()** function will add an extra slash to the pathname before joining it to the filename.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQTpWUJ8fkim",
        "colab_type": "code",
        "outputId": "304cd0a5-f5fa-4e8a-8e58-5eb53d63bc21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open(os.path.join(dataset_root,'train.json'),'r') as train:\n",
        "  train_json=json.load(train)\n",
        "train_json[0]['q_vbs2tango']\n",
        "#len(train_json)\n",
        "type(train_json)\n",
        "# q=train_json[i]['q_vbs2tango']\n",
        "# r=train_json[i]['r_Vo2To_vbs_true']\n",
        "# a=q.extend(r)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y12IBNK5jVlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgname_list=[]\n",
        "for i in range(len(train_json)):\n",
        "  imgname_list.append(train_json[i]['filename'])\n",
        "\n",
        "#imgname_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDL69KMEzqD_",
        "colab_type": "text"
      },
      "source": [
        "Putting all the images and corresponding 7 continuous values (4 from quaternion vector, 3 from position vector) in a Pandas dataframe to be able to use with **flow_from_dataframe** function\n",
        "for multilabel regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLbgD2bUlzzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list=[]\n",
        "q1,q2,q3,q4,r1,r2,r3=[],[],[],[],[],[],[]\n",
        "for i in range(len(train_json)):\n",
        "  q1.append(train_json[i]['q_vbs2tango'][0])\n",
        "  q2.append(train_json[i]['q_vbs2tango'][1])\n",
        "  q3.append(train_json[i]['q_vbs2tango'][2])\n",
        "  q4.append(train_json[i]['q_vbs2tango'][3])\n",
        "  r1.append(train_json[i]['r_Vo2To_vbs_true'][0])\n",
        "  r2.append(train_json[i]['r_Vo2To_vbs_true'][1])\n",
        "  r3.append(train_json[i]['r_Vo2To_vbs_true'][2])\n",
        "  #q.extend(r)\n",
        "  #label_list.append(q)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sfy7lfwlMxp",
        "colab_type": "code",
        "outputId": "0360ad31-7c19-4f24-da3e-ab9a49cc0ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "col_dict={'image_names':imgname_list,'q1':q1,'q2':q2,'q3':q3,'q4':q4,'r1':r1,'r2':r2,'r3':r3}\n",
        "df=pd.DataFrame(col_dict)\n",
        "#df['labels']=label_list\n",
        "df_train,df_test=train_test_split(df,test_size=0.2)\n",
        "len(df_test)\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_names</th>\n",
              "      <th>q1</th>\n",
              "      <th>q2</th>\n",
              "      <th>q3</th>\n",
              "      <th>q4</th>\n",
              "      <th>r1</th>\n",
              "      <th>r2</th>\n",
              "      <th>r3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10572</th>\n",
              "      <td>img013233.jpg</td>\n",
              "      <td>-0.503782</td>\n",
              "      <td>0.646529</td>\n",
              "      <td>-0.444970</td>\n",
              "      <td>-0.360841</td>\n",
              "      <td>0.162846</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>6.359701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>img000660.jpg</td>\n",
              "      <td>0.034388</td>\n",
              "      <td>-0.234132</td>\n",
              "      <td>-0.330508</td>\n",
              "      <td>0.913654</td>\n",
              "      <td>-0.070732</td>\n",
              "      <td>0.089792</td>\n",
              "      <td>9.142628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5819</th>\n",
              "      <td>img007283.jpg</td>\n",
              "      <td>0.446367</td>\n",
              "      <td>-0.806015</td>\n",
              "      <td>0.348459</td>\n",
              "      <td>0.172254</td>\n",
              "      <td>-0.253876</td>\n",
              "      <td>-0.973054</td>\n",
              "      <td>25.551743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2768</th>\n",
              "      <td>img003486.jpg</td>\n",
              "      <td>-0.356865</td>\n",
              "      <td>-0.027647</td>\n",
              "      <td>-0.906469</td>\n",
              "      <td>0.224049</td>\n",
              "      <td>-0.261687</td>\n",
              "      <td>0.113041</td>\n",
              "      <td>16.623442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6256</th>\n",
              "      <td>img007830.jpg</td>\n",
              "      <td>-0.808217</td>\n",
              "      <td>0.101052</td>\n",
              "      <td>-0.535798</td>\n",
              "      <td>0.222473</td>\n",
              "      <td>0.123366</td>\n",
              "      <td>0.225897</td>\n",
              "      <td>23.779483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_names        q1        q2  ...        r1        r2         r3\n",
              "10572  img013233.jpg -0.503782  0.646529  ...  0.162846  0.019178   6.359701\n",
              "520    img000660.jpg  0.034388 -0.234132  ... -0.070732  0.089792   9.142628\n",
              "5819   img007283.jpg  0.446367 -0.806015  ... -0.253876 -0.973054  25.551743\n",
              "2768   img003486.jpg -0.356865 -0.027647  ... -0.261687  0.113041  16.623442\n",
              "6256   img007830.jpg -0.808217  0.101052  ...  0.123366  0.225897  23.779483\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GqXxArr5uxZ",
        "colab_type": "text"
      },
      "source": [
        "Previously, one should have to write a custom generator if they have to perform regression or predict multiple columns and utilize the image augmentation capabilities of the ImageDataGenerator, now we can have the target values as just another column/s (must be numerical datatype) in our dataframe, simply provide the column names to the **flow_from_dataframe** and we can now use all the augmentations provided by the ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcFFc9ZwsKjT",
        "colab_type": "code",
        "outputId": "9efad922-072b-40f0-9782-77ff3daea9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "path=\"/content/gdrive/My Drive/Colab Notebooks/speed/images/train\"\n",
        "cols=['q1','q2','q3','q4','r1','r2','r3']\n",
        "datagen=ImageDataGenerator(preprocessing_function=preprocess_input,zoom_range=0.2,brightness_range=[0.8,1.2]) #Values less than 1.0 darken the image, e.g. [0.5, 1.0], whereas values larger than 1.0 brighten the image, e.g. [1.0, 1.5], where 1.0 has no effect on brightness.\n",
        "datagen2=ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "train_generator=datagen.flow_from_dataframe(df_train,directory=path,x_col='image_names',y_col=cols,class_mode='other',target_size=(299,299),batch_size=32,color_mode='rgb')\n",
        "validation_generator=datagen2.flow_from_dataframe(df_test,directory=path,x_col='image_names',y_col=cols,class_mode='other',target_size=(299,299),batch_size=32,color_mode='rgb')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9600 validated image filenames.\n",
            "Found 2400 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz7seWTinME_",
        "colab_type": "code",
        "outputId": "1c49a85a-0c7e-461e-cd0c-a3c804d8937a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_generator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U3TITUYL-GR",
        "colab_type": "text"
      },
      "source": [
        "**Building our model using Transfer Learning.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1corPUq8Aq8G",
        "colab_type": "code",
        "outputId": "7cd6d808-06bf-43b3-f887-7dee050c16c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "\n",
        "#tensorflow.keras.backend.set_learning_phase(0)\n",
        "model_pretrained=Xception(weights='imagenet',include_top=False,input_shape=(299,299,3))\n",
        "#tensorflow.keras.backend.set_learning_phase(1)\n",
        "\n",
        "#using keras functional api to build our model\n",
        "\n",
        "x=model_pretrained.output\n",
        "\n",
        "#x=Flatten()(x)\n",
        "\n",
        "#x=Dense(32,activation='selu',kernel_initializer='lecun_normal')(x)\n",
        "        \n",
        "#x=BatchNormalization()(x)\n",
        "\n",
        "x=Dense(1024,activation='selu',kernel_initializer='lecun_normal')(x) #\n",
        "   \n",
        "x=AlphaDropout(0.1)(x)\n",
        "        \n",
        "# x=Dense(64,activation='selu',kernel_initializer='lecun_normal')(x) #\n",
        "   \n",
        "# x=AlphaDropout(0.1)(x)\n",
        "\n",
        "#x=BatchNormalization()(x)\n",
        "        \n",
        "#x=Dense(128,activation='selu',kernel_initializer='lecun_normal')(x)\n",
        "        \n",
        "x=Flatten()(x)\n",
        "        \n",
        "x=Dense(7,activation='linear')(x)\n",
        "\n",
        "model=Model(inputs=model_pretrained.input,outputs=x)\n",
        "\n",
        "\n",
        "# step_size_train=train_generator.n//train_generator.batch_size #It should typically be equal to the number of samples of your dataset divided by the batch size.\n",
        "# step_size_valid=validation_generator.n//validation_generator.batch_size\n",
        "# history=model.fit_generator(train_generator,steps_per_epoch=step_size_train,epochs=2,validation_data=validation_generator,validation_steps=step_size_valid)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0725 13:27:40.092952 139808584177536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0725 13:27:40.117626 139808584177536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0725 13:27:40.122889 139808584177536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0725 13:27:40.151213 139808584177536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0725 13:27:40.152497 139808584177536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0725 13:27:40.767540 139808584177536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0725 13:27:41.374673 139808584177536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0725 13:27:48.246258 139808584177536 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3217: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4s9o3uatNyf",
        "colab_type": "text"
      },
      "source": [
        "**IMP** Which layers to train or not should be done before model compilation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ibRWiTdunz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_generator[0][0][0][0][0]\n",
        "# train_generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuJE7xvu-o-X",
        "colab_type": "code",
        "outputId": "367630a0-09e1-4f80-d75f-1c8de8f6ff4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i,j in enumerate(model.layers):\n",
        "  print(i,':',j)\n",
        "for layer in model.layers[:17]:\n",
        "  layer.trainable=False\n",
        "for layer in model.layers[17:]:\n",
        "  layer.trainable=True"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 : <keras.engine.input_layer.InputLayer object at 0x7f2795da7860>\n",
            "1 : <keras.layers.convolutional.Conv2D object at 0x7f2795da7390>\n",
            "2 : <keras.layers.normalization.BatchNormalization object at 0x7f2795da75c0>\n",
            "3 : <keras.layers.core.Activation object at 0x7f2765340240>\n",
            "4 : <keras.layers.convolutional.Conv2D object at 0x7f27510c1f98>\n",
            "5 : <keras.layers.normalization.BatchNormalization object at 0x7f27510e1e80>\n",
            "6 : <keras.layers.core.Activation object at 0x7f2751054cc0>\n",
            "7 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2750ff5400>\n",
            "8 : <keras.layers.normalization.BatchNormalization object at 0x7f2750f0cf98>\n",
            "9 : <keras.layers.core.Activation object at 0x7f2750eb0d68>\n",
            "10 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2750e73240>\n",
            "11 : <keras.layers.normalization.BatchNormalization object at 0x7f2750e24f98>\n",
            "12 : <keras.layers.convolutional.Conv2D object at 0x7f2751024f98>\n",
            "13 : <keras.layers.pooling.MaxPooling2D object at 0x7f2750db27b8>\n",
            "14 : <keras.layers.normalization.BatchNormalization object at 0x7f275103af60>\n",
            "15 : <keras.layers.merge.Add object at 0x7f2750d5e748>\n",
            "16 : <keras.layers.core.Activation object at 0x7f2750c5cef0>\n",
            "17 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2750c5cf98>\n",
            "18 : <keras.layers.normalization.BatchNormalization object at 0x7f2750c082b0>\n",
            "19 : <keras.layers.core.Activation object at 0x7f2750b51c18>\n",
            "20 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2750bb2fd0>\n",
            "21 : <keras.layers.normalization.BatchNormalization object at 0x7f2750b004e0>\n",
            "22 : <keras.layers.convolutional.Conv2D object at 0x7f2750cc3f28>\n",
            "23 : <keras.layers.pooling.MaxPooling2D object at 0x7f2750a4cd68>\n",
            "24 : <keras.layers.normalization.BatchNormalization object at 0x7f2750c5c2e8>\n",
            "25 : <keras.layers.merge.Add object at 0x7f2750ab0e48>\n",
            "26 : <keras.layers.core.Activation object at 0x7f27509b37b8>\n",
            "27 : <keras.layers.convolutional.SeparableConv2D object at 0x7f275091b5c0>\n",
            "28 : <keras.layers.normalization.BatchNormalization object at 0x7f275097bd30>\n",
            "29 : <keras.layers.core.Activation object at 0x7f2750889710>\n",
            "30 : <keras.layers.convolutional.SeparableConv2D object at 0x7f275081e6d8>\n",
            "31 : <keras.layers.normalization.BatchNormalization object at 0x7f275087ce48>\n",
            "32 : <keras.layers.convolutional.Conv2D object at 0x7f27509d92b0>\n",
            "33 : <keras.layers.pooling.MaxPooling2D object at 0x7f2750788f98>\n",
            "34 : <keras.layers.normalization.BatchNormalization object at 0x7f27509b3320>\n",
            "35 : <keras.layers.merge.Add object at 0x7f27507b31d0>\n",
            "36 : <keras.layers.core.Activation object at 0x7f275071f828>\n",
            "37 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2750768b38>\n",
            "38 : <keras.layers.normalization.BatchNormalization object at 0x7f27506b4160>\n",
            "39 : <keras.layers.core.Activation object at 0x7f2750649a58>\n",
            "40 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2750618f28>\n",
            "41 : <keras.layers.normalization.BatchNormalization object at 0x7f275067e390>\n",
            "42 : <keras.layers.core.Activation object at 0x7f275054cba8>\n",
            "43 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27505b79b0>\n",
            "44 : <keras.layers.normalization.BatchNormalization object at 0x7f275057d320>\n",
            "45 : <keras.layers.merge.Add object at 0x7f2750449cf8>\n",
            "46 : <keras.layers.core.Activation object at 0x7f275073f8d0>\n",
            "47 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27504afac8>\n",
            "48 : <keras.layers.normalization.BatchNormalization object at 0x7f27503eadd8>\n",
            "49 : <keras.layers.core.Activation object at 0x7f27503b1be0>\n",
            "50 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2750339470>\n",
            "51 : <keras.layers.normalization.BatchNormalization object at 0x7f2750319ef0>\n",
            "52 : <keras.layers.core.Activation object at 0x7f27502a6da0>\n",
            "53 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27502355c0>\n",
            "54 : <keras.layers.normalization.BatchNormalization object at 0x7f2750216d30>\n",
            "55 : <keras.layers.merge.Add object at 0x7f27501a6e80>\n",
            "56 : <keras.layers.core.Activation object at 0x7f27504afdd8>\n",
            "57 : <keras.layers.convolutional.SeparableConv2D object at 0x7f275014bc50>\n",
            "58 : <keras.layers.normalization.BatchNormalization object at 0x7f27500d86d8>\n",
            "59 : <keras.layers.core.Activation object at 0x7f27500a7eb8>\n",
            "60 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27500693c8>\n",
            "61 : <keras.layers.normalization.BatchNormalization object at 0x7f275001af60>\n",
            "62 : <keras.layers.core.Activation object at 0x7f2719403898>\n",
            "63 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27193c7518>\n",
            "64 : <keras.layers.normalization.BatchNormalization object at 0x7f2719376f98>\n",
            "65 : <keras.layers.merge.Add object at 0x7f27193009e8>\n",
            "66 : <keras.layers.core.Activation object at 0x7f275014b048>\n",
            "67 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27192af668>\n",
            "68 : <keras.layers.normalization.BatchNormalization object at 0x7f2719235198>\n",
            "69 : <keras.layers.core.Activation object at 0x7f27191af6a0>\n",
            "70 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27191afd68>\n",
            "71 : <keras.layers.normalization.BatchNormalization object at 0x7f2719178320>\n",
            "72 : <keras.layers.core.Activation object at 0x7f27190c6cf8>\n",
            "73 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27190aeb00>\n",
            "74 : <keras.layers.normalization.BatchNormalization object at 0x7f2718fe5dd8>\n",
            "75 : <keras.layers.merge.Add object at 0x7f2718faec18>\n",
            "76 : <keras.layers.core.Activation object at 0x7f27192af978>\n",
            "77 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2718faeb00>\n",
            "78 : <keras.layers.normalization.BatchNormalization object at 0x7f2718f53240>\n",
            "79 : <keras.layers.core.Activation object at 0x7f2718eafcc0>\n",
            "80 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2718e315c0>\n",
            "81 : <keras.layers.normalization.BatchNormalization object at 0x7f2718e93d30>\n",
            "82 : <keras.layers.core.Activation object at 0x7f2718da3e80>\n",
            "83 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2718d38710>\n",
            "84 : <keras.layers.normalization.BatchNormalization object at 0x7f2718d92dd8>\n",
            "85 : <keras.layers.merge.Add object at 0x7f2718ca3fd0>\n",
            "86 : <keras.layers.core.Activation object at 0x7f2718fc7f60>\n",
            "87 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2718cce1d0>\n",
            "88 : <keras.layers.normalization.BatchNormalization object at 0x7f2718c54940>\n",
            "89 : <keras.layers.core.Activation object at 0x7f2718ba5c18>\n",
            "90 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2718b67748>\n",
            "91 : <keras.layers.normalization.BatchNormalization object at 0x7f2718b94f98>\n",
            "92 : <keras.layers.core.Activation object at 0x7f2718aa19e8>\n",
            "93 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2718a6a898>\n",
            "94 : <keras.layers.normalization.BatchNormalization object at 0x7f2718a971d0>\n",
            "95 : <keras.layers.merge.Add object at 0x7f27189a5b38>\n",
            "96 : <keras.layers.core.Activation object at 0x7f2718cce518>\n",
            "97 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27189d07b8>\n",
            "98 : <keras.layers.normalization.BatchNormalization object at 0x7f2718958cc0>\n",
            "99 : <keras.layers.core.Activation object at 0x7f27188d28d0>\n",
            "100 : <keras.layers.convolutional.SeparableConv2D object at 0x7f271886d6a0>\n",
            "101 : <keras.layers.normalization.BatchNormalization object at 0x7f2718807eb8>\n",
            "102 : <keras.layers.core.Activation object at 0x7f27187cec18>\n",
            "103 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27187cef28>\n",
            "104 : <keras.layers.normalization.BatchNormalization object at 0x7f27187582b0>\n",
            "105 : <keras.layers.merge.Add object at 0x7f27186d0da0>\n",
            "106 : <keras.layers.core.Activation object at 0x7f27189d0ac8>\n",
            "107 : <keras.layers.convolutional.SeparableConv2D object at 0x7f271866b940>\n",
            "108 : <keras.layers.normalization.BatchNormalization object at 0x7f27185f4320>\n",
            "109 : <keras.layers.core.Activation object at 0x7f27185c2da0>\n",
            "110 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2718553710>\n",
            "111 : <keras.layers.normalization.BatchNormalization object at 0x7f2718532dd8>\n",
            "112 : <keras.layers.core.Activation object at 0x7f27184bffd0>\n",
            "113 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2718484208>\n",
            "114 : <keras.layers.normalization.BatchNormalization object at 0x7f2718435f60>\n",
            "115 : <keras.layers.merge.Add object at 0x7f27183c3fd0>\n",
            "116 : <keras.layers.core.Activation object at 0x7f27182af668>\n",
            "117 : <keras.layers.convolutional.SeparableConv2D object at 0x7f271823af28>\n",
            "118 : <keras.layers.normalization.BatchNormalization object at 0x7f271829cef0>\n",
            "119 : <keras.layers.core.Activation object at 0x7f271816cda0>\n",
            "120 : <keras.layers.convolutional.SeparableConv2D object at 0x7f27181d3a20>\n",
            "121 : <keras.layers.normalization.BatchNormalization object at 0x7f271815c240>\n",
            "122 : <keras.layers.convolutional.Conv2D object at 0x7f2718320e10>\n",
            "123 : <keras.layers.pooling.MaxPooling2D object at 0x7f27180d6d30>\n",
            "124 : <keras.layers.normalization.BatchNormalization object at 0x7f27182c3828>\n",
            "125 : <keras.layers.merge.Add object at 0x7f271806cf98>\n",
            "126 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2717ffa4a8>\n",
            "127 : <keras.layers.normalization.BatchNormalization object at 0x7f2717f727b8>\n",
            "128 : <keras.layers.core.Activation object at 0x7f2717f88a58>\n",
            "129 : <keras.layers.convolutional.SeparableConv2D object at 0x7f2717f53f28>\n",
            "130 : <keras.layers.normalization.BatchNormalization object at 0x7f2717f36b00>\n",
            "131 : <keras.layers.core.Activation object at 0x7f2717e5ffd0>\n",
            "132 : <keras.layers.core.Dense object at 0x7f271866bf28>\n",
            "133 : <keras.layers.noise.AlphaDropout object at 0x7f2795da7748>\n",
            "134 : <keras.layers.core.Flatten object at 0x7f27177cd3c8>\n",
            "135 : <keras.layers.core.Dense object at 0x7f2795da7630>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOnecUjTQuCG",
        "colab_type": "code",
        "outputId": "f0b95bf9-a164-4112-fe44-f4a3b33c9124",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 74, 74, 128)  512         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 37, 37, 256)  1024        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 19, 19, 728)  2912        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10, 10, 1024) 2098176     block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "alpha_dropout_1 (AlphaDropout)  (None, 10, 10, 1024) 0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 102400)       0           alpha_dropout_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 7)            716807      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,676,463\n",
            "Trainable params: 23,567,183\n",
            "Non-trainable params: 109,280\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ52TuABAa8v",
        "colab_type": "code",
        "outputId": "8ffbf187-13e4-40de-aaaf-39ab2144cc54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "sgd=keras.optimizers.sgd(lr=1e-5,decay=0, momentum=0.9, nesterov=True)\n",
        "adam=keras.optimizers.adam(lr=1e-5)\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=3, min_lr=1e-10,mode='min',verbose=1)\n",
        "early_stopping=keras.callbacks.EarlyStopping(monitor='val_loss',patience=5,verbose=1,mode='min',min_delta=0.01,restore_best_weights=True)\n",
        "model.compile(optimizer=sgd,loss='mean_squared_error') #,metrics=['mse']\n",
        "step_size_train=train_generator.n//train_generator.batch_size #It should typically be equal to the number of samples of your dataset divided by the batch size.\n",
        "step_size_valid=validation_generator.n//validation_generator.batch_size\n",
        "history=model.fit_generator(train_generator,steps_per_epoch=step_size_train,epochs=50,validation_data=validation_generator,validation_steps=step_size_valid,callbacks=[reduce_lr]) #,early_stopping\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0725 13:27:48.575665 139808584177536 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "300/300 [==============================] - 7315s 24s/step - loss: 4.6838 - val_loss: 3.6280\n",
            "Epoch 2/50\n",
            "300/300 [==============================] - 696s 2s/step - loss: 2.8705 - val_loss: 3.3581\n",
            "Epoch 3/50\n",
            "300/300 [==============================] - 694s 2s/step - loss: 2.4522 - val_loss: 3.1343\n",
            "Epoch 4/50\n",
            "300/300 [==============================] - 700s 2s/step - loss: 2.2458 - val_loss: 2.9438\n",
            "Epoch 5/50\n",
            "300/300 [==============================] - 699s 2s/step - loss: 2.1260 - val_loss: 2.7445\n",
            "Epoch 6/50\n",
            "300/300 [==============================] - 700s 2s/step - loss: 1.9920 - val_loss: 2.9818\n",
            "Epoch 7/50\n",
            "300/300 [==============================] - 693s 2s/step - loss: 1.8832 - val_loss: 2.9747\n",
            "Epoch 8/50\n",
            "300/300 [==============================] - 694s 2s/step - loss: 1.8764 - val_loss: 2.9707\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "Epoch 9/50\n",
            "300/300 [==============================] - 689s 2s/step - loss: 1.7545 - val_loss: 2.6617\n",
            "Epoch 10/50\n",
            "300/300 [==============================] - 686s 2s/step - loss: 1.7831 - val_loss: 2.6893\n",
            "Epoch 11/50\n",
            "300/300 [==============================] - 682s 2s/step - loss: 1.7945 - val_loss: 2.6821\n",
            "Epoch 12/50\n",
            "300/300 [==============================] - 681s 2s/step - loss: 1.7587 - val_loss: 2.7093\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "Epoch 13/50\n",
            "300/300 [==============================] - 673s 2s/step - loss: 1.7836 - val_loss: 2.7159\n",
            "Epoch 14/50\n",
            "300/300 [==============================] - 667s 2s/step - loss: 1.7836 - val_loss: 2.6790\n",
            "Epoch 15/50\n",
            "300/300 [==============================] - 669s 2s/step - loss: 1.7763 - val_loss: 2.6446\n",
            "Epoch 16/50\n",
            "300/300 [==============================] - 669s 2s/step - loss: 1.7485 - val_loss: 2.6384\n",
            "Epoch 17/50\n",
            "300/300 [==============================] - 662s 2s/step - loss: 1.7175 - val_loss: 2.6391\n",
            "Epoch 18/50\n",
            "300/300 [==============================] - 658s 2s/step - loss: 1.7830 - val_loss: 2.6065\n",
            "Epoch 19/50\n",
            "300/300 [==============================] - 656s 2s/step - loss: 1.7781 - val_loss: 2.6679\n",
            "Epoch 20/50\n",
            "300/300 [==============================] - 655s 2s/step - loss: 1.7429 - val_loss: 2.6121\n",
            "Epoch 21/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7798 - val_loss: 2.6260\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
            "Epoch 22/50\n",
            "300/300 [==============================] - 656s 2s/step - loss: 1.7230 - val_loss: 2.6371\n",
            "Epoch 23/50\n",
            "300/300 [==============================] - 655s 2s/step - loss: 1.7299 - val_loss: 2.6333\n",
            "Epoch 24/50\n",
            "300/300 [==============================] - 653s 2s/step - loss: 1.7653 - val_loss: 2.6175\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
            "Epoch 25/50\n",
            "300/300 [==============================] - 653s 2s/step - loss: 1.7604 - val_loss: 2.6456\n",
            "Epoch 26/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7549 - val_loss: 2.6272\n",
            "Epoch 27/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7450 - val_loss: 2.6445\n",
            "\n",
            "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 28/50\n",
            "300/300 [==============================] - 656s 2s/step - loss: 1.7486 - val_loss: 2.6589\n",
            "Epoch 29/50\n",
            "300/300 [==============================] - 655s 2s/step - loss: 1.7837 - val_loss: 2.6523\n",
            "Epoch 30/50\n",
            "300/300 [==============================] - 653s 2s/step - loss: 1.7560 - val_loss: 2.6158\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 31/50\n",
            "300/300 [==============================] - 658s 2s/step - loss: 1.7823 - val_loss: 2.6553\n",
            "Epoch 32/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7507 - val_loss: 2.6614\n",
            "Epoch 33/50\n",
            "300/300 [==============================] - 653s 2s/step - loss: 1.7461 - val_loss: 2.6112\n",
            "\n",
            "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 34/50\n",
            "300/300 [==============================] - 656s 2s/step - loss: 1.7746 - val_loss: 2.6484\n",
            "Epoch 35/50\n",
            "300/300 [==============================] - 657s 2s/step - loss: 1.7514 - val_loss: 2.6324\n",
            "Epoch 36/50\n",
            "300/300 [==============================] - 653s 2s/step - loss: 1.7782 - val_loss: 2.6429\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 37/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7602 - val_loss: 2.6244\n",
            "Epoch 38/50\n",
            "300/300 [==============================] - 655s 2s/step - loss: 1.7847 - val_loss: 2.6034\n",
            "Epoch 39/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7705 - val_loss: 2.6532\n",
            "Epoch 40/50\n",
            "300/300 [==============================] - 653s 2s/step - loss: 1.7456 - val_loss: 2.6733\n",
            "Epoch 41/50\n",
            "300/300 [==============================] - 656s 2s/step - loss: 1.7634 - val_loss: 2.6563\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 42/50\n",
            "300/300 [==============================] - 657s 2s/step - loss: 1.7738 - val_loss: 2.6500\n",
            "Epoch 43/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7775 - val_loss: 2.6565\n",
            "Epoch 44/50\n",
            "300/300 [==============================] - 658s 2s/step - loss: 1.7398 - val_loss: 2.6408\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 45/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7629 - val_loss: 2.6090\n",
            "Epoch 46/50\n",
            "300/300 [==============================] - 656s 2s/step - loss: 1.7646 - val_loss: 2.6378\n",
            "Epoch 47/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7193 - val_loss: 2.6587\n",
            "\n",
            "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1e-10.\n",
            "Epoch 48/50\n",
            "300/300 [==============================] - 658s 2s/step - loss: 1.7365 - val_loss: 2.6767\n",
            "Epoch 49/50\n",
            "300/300 [==============================] - 660s 2s/step - loss: 1.7696 - val_loss: 2.6315\n",
            "Epoch 50/50\n",
            "300/300 [==============================] - 654s 2s/step - loss: 1.7584 - val_loss: 2.6233\n",
            "\n",
            "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1e-10.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz2FLxagH-Y3",
        "colab_type": "code",
        "outputId": "49c61aa1-f5b8-42af-ef43-f69add810560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "\n",
        "for e,v in enumerate(history.history['val_loss']):\n",
        "  print(\"Epoch \",e,\":\",v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 : 3.6279833920796714\n",
            "Epoch  1 : 3.3581006224950154\n",
            "Epoch  2 : 3.1342660061518353\n",
            "Epoch  3 : 2.943791054089864\n",
            "Epoch  4 : 2.7444564723968505\n",
            "Epoch  5 : 2.9818450768788654\n",
            "Epoch  6 : 2.9746910309791565\n",
            "Epoch  7 : 2.97069539864858\n",
            "Epoch  8 : 2.6616809860865276\n",
            "Epoch  9 : 2.6892836419741313\n",
            "Epoch  10 : 2.682108572324117\n",
            "Epoch  11 : 2.7093078072865806\n",
            "Epoch  12 : 2.7158721780776975\n",
            "Epoch  13 : 2.6789696804682412\n",
            "Epoch  14 : 2.6446347443262734\n",
            "Epoch  15 : 2.6383742356300353\n",
            "Epoch  16 : 2.639083806673686\n",
            "Epoch  17 : 2.6064956760406495\n",
            "Epoch  18 : 2.6679451656341553\n",
            "Epoch  19 : 2.6121174494425454\n",
            "Epoch  20 : 2.6259576710065207\n",
            "Epoch  21 : 2.6371215836207074\n",
            "Epoch  22 : 2.6333155552546184\n",
            "Epoch  23 : 2.617523792584737\n",
            "Epoch  24 : 2.6455794843037923\n",
            "Epoch  25 : 2.6272151589393617\n",
            "Epoch  26 : 2.6445490582784017\n",
            "Epoch  27 : 2.658919450441996\n",
            "Epoch  28 : 2.6523090902964275\n",
            "Epoch  29 : 2.6158246405919394\n",
            "Epoch  30 : 2.6553436660766603\n",
            "Epoch  31 : 2.661392642656962\n",
            "Epoch  32 : 2.6112119913101197\n",
            "Epoch  33 : 2.6484089581171673\n",
            "Epoch  34 : 2.632421464920044\n",
            "Epoch  35 : 2.642886771361033\n",
            "Epoch  36 : 2.62437397480011\n",
            "Epoch  37 : 2.6034430583318073\n",
            "Epoch  38 : 2.6531622513135273\n",
            "Epoch  39 : 2.673332858880361\n",
            "Epoch  40 : 2.656295824050903\n",
            "Epoch  41 : 2.6499942223231\n",
            "Epoch  42 : 2.656491480668386\n",
            "Epoch  43 : 2.640810418923696\n",
            "Epoch  44 : 2.6089669116338094\n",
            "Epoch  45 : 2.6378272485733034\n",
            "Epoch  46 : 2.6587111886342365\n",
            "Epoch  47 : 2.6767011229197184\n",
            "Epoch  48 : 2.6314683787027993\n",
            "Epoch  49 : 2.623280881245931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWp83iCg6ZnP",
        "colab_type": "code",
        "outputId": "985e90e4-ff45-4ccc-95f8-948b84580ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8XNWd9/HPTzPqzbIsybZkW7g3\nXLAxpgSIKaEF2FBCFpKQZCF5kl0gySYbnic9m81mN5ueLQSyIQkBQksIJKFDwICNXHHFNq6yLcmy\nZPU65/njXMuyLNlqo5E93/frNS+NZu7M/O5oNN97zr33HHPOISIiApAQ6wJERGT4UCiIiEgHhYKI\niHRQKIiISAeFgoiIdFAoiIhIB4WCSC+Z2S/N7J97uewOM7t4oM8jMtQUCiIi0kGhICIiHRQKckoJ\num2+YGZrzazezO4zswIz+7OZ1ZrZ82aW02n5q81svZlVm9nLZjaj033zzWxl8LiHgZQur3WVma0O\nHvu6mc3pZ823mdlWMztoZk+a2djgdjOzH5hZuZnVmNnbZjY7uO8KM9sQ1FZqZv/YrzdMpAuFgpyK\nrgMuAaYC7wf+DPxfIA//mb8DwMymAg8CdwX3/Qn4o5klmVkS8Hvg18BI4JHgeQkeOx/4BfBJIBf4\nH+BJM0vuS6FmtgT4DnAjMAbYCTwU3H0pcH6wHtnBMpXBffcBn3TOZQKzgRf78roiPVEoyKnoJ865\nMudcKfAqsMw5t8o51wQ8AcwPlvsg8LRz7jnnXCvwPSAVOAdYDCQCP3TOtTrnHgXe6vQatwP/45xb\n5pxrd87dDzQHj+uLm4FfOOdWOueagbuBs82sGGgFMoHpgDnnNjrn9gWPawVmmlmWc67KObeyj68r\n0i2FgpyKyjpdb+zm94zg+lj8ljkAzrkIsBsoDO4rdUePGLmz0/UJwOeDrqNqM6sGxgWP64uuNdTh\nWwOFzrkXgZ8CPwPKzeweM8sKFr0OuALYaWavmNnZfXxdkW4pFCSe7cV/uQO+Dx//xV4K7AMKg9sO\nG9/p+m7g2865EZ0uac65BwdYQzq+O6oUwDn3Y+fcAmAmvhvpC8HtbznnrgHy8d1cv+vj64p0S6Eg\n8ex3wJVmdpGZJQKfx3cBvQ68AbQBd5hZopl9AFjU6bE/Bz5lZmcFO4TTzexKM8vsYw0PAh8zs3nB\n/oh/wXd37TCzM4PnTwTqgSYgEuzzuNnMsoNurxogMoD3QaSDQkHilnNuM3AL8BPgAH6n9Pudcy3O\nuRbgA8CtwEH8/ofHOz22BLgN371TBWwNlu1rDc8DXwEew7dOJgE3BXdn4cOnCt/FVAn8e3Dfh4Ed\nZlYDfAq/b0JkwEyT7IiIyGFqKYiISAeFgoiIdFAoiIhIB4WCiIh0CMe6gL4aNWqUKy4ujnUZIiIn\nlRUrVhxwzuWdaLmTLhSKi4spKSmJdRkiIicVM9t54qXUfSQiIp0oFEREpINCQUREOigURESkg0JB\nREQ6KBRERKSDQkFERDrETShs2l/D957ZzMH6lliXIiIybMVNKGyvqOenL21l/6GmWJciIjJsxU0o\npCf7k7frW9piXImIyPAVd6FQ16xQEBHpSdyEQsbhloJCQUSkR3ETCunJIUChICJyPHETCpnJiQDU\nNbfHuBIRkeErbkLhcEuhrkktBRGRnsRNKIRDCSSHE3T0kYjIccRNKIDf2ayjj0REehb1UDCzkJmt\nMrOnurnvVjOrMLPVweXvollLenJYO5pFRI5jKKbjvBPYCGT1cP/Dzrm/H4I6FAoiIicQ1ZaCmRUB\nVwL3RvN1eitT3UciIscV7e6jHwJfBCLHWeY6M1trZo+a2bjuFjCz282sxMxKKioq+l1MenJIoSAi\nchxRCwUzuwood86tOM5ifwSKnXNzgOeA+7tbyDl3j3NuoXNuYV5eXr9r8t1HOk9BRKQn0WwpnAtc\nbWY7gIeAJWb2m84LOOcqnXPNwa/3AguiWI+OPhIROYGohYJz7m7nXJFzrhi4CXjROXdL52XMbEyn\nX6/G75COGu1oFhE5vqE4+ugoZvZNoMQ59yRwh5ldDbQBB4Fbo/na6clhGlraiUQcCQkWzZcSETkp\nDUkoOOdeBl4Orn+10+13A3cPRQ3gjz4CP6dCZkriUL2siMhJI67OaO6YaEc7m0VEuhVnoRAMitfc\nGuNKRESGp7gKhYyO2dfUUhAR6U5chUK6Zl8TETmuuAqFDM3TLCJyXHEVCmopiIgcX1yFQoZCQUTk\nuOIyFGoVCiIi3YqrUEhJTCDB1FIQEelJXIWCmWmkVBGR44irUACNlCoicjxxFwoaKVVEpGdxFwpq\nKYiI9EyhICIiHeIuFNKTQ+o+EhHpQRyGgo4+EhHpSdyFgrqPRER6FnehcPjoI+dcrEsRERl24i4U\nMpLDtEUczW2RWJciIjLsxGUogIbPFhHpTtyFgobPFhHpWdyFQkbHPM0KBRGRruIuFI60FHRYqohI\nV3EcCmopiIh0FXehkKkdzSIiPYp6KJhZyMxWmdlT3dyXbGYPm9lWM1tmZsXRrkctBRGRng1FS+FO\nYGMP930CqHLOTQZ+AHw32sWkq6UgItKjqIaCmRUBVwL39rDINcD9wfVHgYvMzKJZU3qSjj4SEelJ\ntFsKPwS+CPR0+nAhsBvAOdcGHAJyuy5kZrebWYmZlVRUVAyooHAogZTEBHUfiYh0I2qhYGZXAeXO\nuRUDfS7n3D3OuYXOuYV5eXkDrs0PiqdDUkVEuopmS+Fc4Goz2wE8BCwxs990WaYUGAdgZmEgG6iM\nYk2ApuQUEelJ1ELBOXe3c67IOVcM3AS86Jy7pctiTwIfDa5fHywT9eFLMxQKIiLdCg/1C5rZN4ES\n59yTwH3Ar81sK3AQHx5Rl54cplahICJyjCEJBefcy8DLwfWvdrq9CbhhKGroLCM5TFlN01C/rIjI\nsBd3ZzSD9imIiPQkLkMhIzmko49ERLoRl6GQnqSWgohId+IyFDJSwjS2ttMe0TzNIiKdxWcoaPwj\nEZFuxWUoaKRUEZHuKRRERKRDXIaC5mkWEeleXIZCepLmaRYR6U5chkJGinY0i4h0Jz5DQfsURES6\nFZehoCk5RUS6F5ehoPMURES6F5ehkBxOIJRg6j4SEekiLkPBzEhPCikURES6iMtQAMhMSdRIqSIi\nXcRtKKQnq6UgItJV/ISCc7B3lf+JPwJJO5pFRI4WP6Gw6jdwz4VQvgHwRyApFEREjhY/oTD1MrAQ\nrHsM0EQ7IiLdiZ9QyMiDiRf4UHBO8zSLiHQjfkIBYPb1ULUDSlcG8zQrFEREOouvUJh+JYSSYN2j\nZKSEqW9pxzlNySkiclh8hULqCJhyKax7nIwkoz3iaGqNxLoqEZFhI2qhYGYpZrbczNaY2Xoz+0Y3\ny9xqZhVmtjq4/F206ukw+wNQt5+JDWsBjX8kItJZNFsKzcAS59xcYB5wmZkt7ma5h51z84LLvVGs\nx5t6GSSmMaX8WUDDZ4uIdBa1UHBeXfBrYnCJfQd+UjpMu4Kifc8Spk0tBRGRTqK6T8HMQma2GigH\nnnPOLetmsevMbK2ZPWpm43p4ntvNrMTMSioqKgZe2OzrSGqp5ryEdWopiIh0EtVQcM61O+fmAUXA\nIjOb3WWRPwLFzrk5wHPA/T08zz3OuYXOuYV5eXkDL2zyRbQlZfH+0BvUtygUREQOG5Kjj5xz1cBL\nwGVdbq90zjUHv94LLBiKeggn0zDxci5NKKGhoX5IXlJE5GQQzaOP8sxsRHA9FbgE2NRlmTGdfr0a\n2BiterpqnXkdmdZI1u6Xh+olRUSGvWi2FMYAL5nZWuAt/D6Fp8zsm2Z2dbDMHcHhqmuAO4Bbo1jP\nURInn0+Fy6Ko9E9D9ZIiIsNeOFpP7JxbC8zv5vavdrp+N3B3tGo4nvSUFJ5oP4ubD/wVmmshOTMW\nZYiIDCvxdUZzJ6EE4xk7j3CkGTb/OdbliIgMC3EbCgBbk2dSnZgPbz8a61JERIaFuA6F9JQkSjKW\nwLYXoOFgrMsREYm5+A6F5BCvJZ8PkTZY/3isyxERibn4DoWkMBvcaTB6Drx1X8f8zSIi8SquQyEj\nOUxdSzssus3P3bzrjViXJCISU3EdCunJYT/MxezrISUblv881iWJiMSUQqG5DZLSYN4tsPFJqC2L\ndVkiIjHTq1AwszvNLMu8+8xspZldGu3ioi0zJXxk6OwzP+F3OK/sdkw+EZG40NuWwsedczXApUAO\n8GHgX6NW1RBJTwrT1BqhrT0CuZNg0hIo+V9o18ipIhKfehsKFvy8Avi1c259p9tOWunJIQDqm9v9\nDWfeBrV7YbPGQxKR+NTbUFhhZs/iQ+EZM8sETvoZ7zOS/dBPdYfnVJj6PsgeB29ph7OIxKfehsIn\ngC8BZzrnGvBTa34salUNkfQgFDpmX0sIwcKPwfa/QsXmGFYmIhIbvQ2Fs4HNzrlqM7sF+DJwKHpl\nDY2OlkLnKTnnfwRCSf5kNhGRONPbUPgvoMHM5gKfB7YBv4paVUMkI6VLSwEgIw9mXgtrHoTmuhhV\nJiISG70NhTbnnAOuAX7qnPsZcNJPQJCe1E0oAJz5d9BcA2//LgZViYjETm9DodbM7sYfivq0mSXg\n9yuc1A53H9U2dQmFcYtg9Omw/F6NhyQicaW3ofBBoBl/vsJ+oAj496hVNUSOHJLaJRTMfGuhfD3s\nejMGlYmIxEavQiEIggeAbDO7Cmhyzp30+xQ6jj5qaT/2ztNv8OMhvfmzIa5KRCR2ejvMxY3AcuAG\n4EZgmZldH83ChkJyOIFwgh199NFhSemw6HbY+Eco2zD0xYmIxEBvu4/+H/4chY865z4CLAK+Er2y\nhoaZkZESPrb76LDFn4akDHj1e0NbmIhIjPQ2FBKcc+Wdfq/sw2OHtfSkcPctBYC0kX7fwrrHoeKd\noS1MRCQGevvF/hcze8bMbjWzW4GngVNigKCM5DB1XY8+6uzsv4dwCrz6H0NXlIhIjPR2R/MXgHuA\nOcHlHufcP0WzsKGSnhzyE+30JCMPFn4c3n4EDr47dIWJiMRAr7uAnHOPOec+F1yeONHyZpZiZsvN\nbI2ZrTezb3SzTLKZPWxmW81smZkV9638gUtPDlPX3M3RR52dewckhOHV7w9NUSIiMXLcUDCzWjOr\n6eZSa2Y1J3juZmCJc24uMA+4zMwWd1nmE0CVc24y8APgu/1dkf7KSD7OjubDMkfDgo/6oS+qdg5N\nYSIiMXDcUHDOZTrnsrq5ZDrnsk7wWOecOzx4UGJw6Xp68DXA4anOHgUuMrMhnaehV6EAcO6dgMHS\nH0a9JhGRWInqEURmFjKz1UA58JxzblmXRQqB3QDOuTb8yKu53TzP7WZWYmYlFRUVg1qj7z7qRShk\nF8H8W2DVb+BQad9fqLkW2lv7/jgRkSEUjuaTO+fagXlmNgJ4wsxmO+fW9eN57sHv6GbhwoWDOhjR\n4ZaCc44TNlLO+yys+jUs/RFc8W+9f5EdS+GXV/jryVn+UNfUkZCW668nZUBSGiSmBz/T/G0TL4Cs\nsf1fORGRPopqKBwWzMPwEnAZ0DkUSoFxwB4zCwPZ+HMghkx6cpiIg8bWdtKSTvB25EyAOTfByvvh\nPZ+HzILevcjyeyA1x58M11AZXA5CfYWfzKelDloboK3p6MdNuRRufqR/KyYi0g9RCwUzywNag0BI\nBS7h2B3JTwIfBd4ArgdeDIboHjIZwaB4dc1tJw4FgPd8Dtb8Fl7/Mbzv2ydevv4AbHoaFt0GF3zx\n+MtG2n04tDTAy9+B1b+Flno/5IaIyBCI5j6FMcBLZrYWeAu/T+EpM/ummV0dLHMfkGtmW4HP4af8\nHFJHpuQ8wWGph+VOgtnXQ8n/+q39E1nzIERa4YyPnHjZhBAkZ/oWyOwPQHszbHupd3WJiAyCqLUU\nnHNrgfnd3P7VTteb8IPsxcwx8zT3xnl3+Ql4lv8cLjzOOXzOwcpfQdEiyJ/Rt8LGnw3J2bD5zzDj\nqr49VkSkn06J8YsGIrO7eZpPpGAWTL0Mlv23797pya434cA7/hyHvgolwpSLYcszEIn0/fEiIv0Q\n96HQr5YCwLl3QeNBf4hqT1b+CpIyYdbf9K+4qZf7ndGlK/r3eBGRPlIo9KelADDhbBi3GF7/Sffn\nHzRWw/on4PTr+7+jeMrFYCF458/9e7yISB/FfSgUZCVjBjsONPT9wed9Fg7t9kNrd/X2I9DW2Lsd\nzD1JzYEJ5/j9CiIiQyDuQyEzJZGp+Zms3FXV9wdPuRTyZ8JrPzi233/lr2D06TD2mH3tfTP1Mijf\noDGXRGRIxH0oAJwxYQSrdlURifTxFImEBD8mUsVG2PLskdv3roL9a+GMj8JAh3Kadrn/+c5fBvY8\nIiK9oFAA5o/PoaapjXcP1J144a5mXwfZ444eKG/lr/zEPKcPwtG2uZMgd4q6kERkSCgUgDPG5wCw\ncmd13x8cSoRz/gF2vQE73/CHqK59BGZeC6kjBqfAaZfDjteg6USjlYuIDIxCAZg4Kp3s1MT+7VcA\nmP9hP7jd0h/C+t9DS23/zk3oybTL/VnR214YvOcUEemGQgFISDDmjx/R/1BISoNFn/T9/n/9N9/d\nM/7swSuwaJE/Emmz9iuISHQpFAJnjM9hS3kdNU39nPNg0W1+6OuqHf4w1MGcKygU9kc6bXkW2vt4\nPoWISB8oFAJnjM/BOVi9qx/7FcDPi3DmxyGcCnM/NLjFgT80tfEg7Fk++M8tIhJQKATmjsvGjP53\nIQFc9DX4hxLIyBu8wg6bfBEkhAf/KCTn/A7sqp2wd7UflXXd41C60t8nInFlSCbZORlkpiQyrSCT\nlf1tKYA/Eim7aPCK6iwlG4rP8/stLv1W/5+nuQ62vwLvPOMDoKYUXA/Dhhec7neYn37D4B1JJSLD\nmkKhk/njc3hq7V4iEUdCwiDuExgsUy+Hv/wTVG7z5y8cVrvf72/Yv86HR1qnqT7TciEhEXa86oNg\n51Job/ED9U26EObc6Hdip+b4L/7UHP8cu970M8z96R/h2a/4Qf0WfBTGnTW4+0tEZFhRKHRyxvgR\nPLh8F9sq6phSkBnrco417TIfCpv/BBPO9V/yW57xZ1CDn9e5pR7oodtn1DRYdDtMfZ8fzC+c1PNr\nFcyCMz/hn3vF/fD2o37GuVFT/T6TOR+E7MJBX8UetbdC0yFIHzV0rynDS10FlJbA/rchI9+3ZPNn\n+KP/TgYt9VC2Hvat8ZfGKj/qwZRLhtWGlkKhkzMmBCex7aoanqGQUwx5M+DZLwc3GBSdCUu+4ndE\nF8wCF/Ffnp3ngm6ph6KFMPK0vr/m2Pn+cuk/w/rHYdUD8MI34IVvwsQLfEDMeH90pwwtXQF/+Hs4\nsAXO/jSc/0VIzoje6w2V1iY4uM3PuXFgKzRVB621kZ1abzmQNdZ/CfZGJOJbhdU7/eegsdo/b9Mh\nf8mb7od9T8+N7roNlHN+v9ae5bDnLdhT4tfpGOZbzQWzYfRsyB5/pNWbMuLIdSx4P6r8+9FY5S/t\nrTBqin9fUrIGr/62Fh9ee5b7z+++tVC5xf9/gv8bh5Jg01MwZi6c/wWYdqUfOifGbIinRB6whQsX\nupKSkqg8t3OO+d96jvfNHM13r58TldcYsPVPwKY/+R3Pky+OzZbzwXdhzcN+qtHqnf5Q3KmXQlbh\n0f+MKSN8V5Ql+H+GzhecH0wwbWTPr9Pa5Oeqfv3HkFHgz/1Y/zhkjvXzY8/6m75vYTnnwzLSDomp\nkJjmD/ntq+pd/ryRPW/ByIn+H3vMXP8F3rWm9lao2Axl6/wXRcUmH3DVuziqVRdO9SPrdue0C3z3\n3fSrIJx87P2N1bD6AT8bYNX2I7dbgv8bpIzwQVq23rcoz70DFn+65zAvW+9biDtehRET/BZ5/kz/\nc9SUIzW0Nvn9UjV7j/xMHwVj5vllQ4m9fks77HgNnv+6f2/Bf64KF/gNoKKFMHqOn2ekbJ3vMi0L\nLlU7+v5anWUV+nDIn+E3sCZf0vuDRuor/agGu5f5uveugrYmf1/m2COfjzFzfP3ZRRBpg7UPw6v/\n4f+n8mbA+f/oP9cJoYGtSzfMbIVzbuEJl1MoHO1j/7ucPVWNPPe5C6L2GqcM5/w/wpoHYeuL/pDZ\n1j4MQZ4QhkkX+Tknpl1x9Nb/7uXwh8/4rej5t8Cl3/aBs3s5PP15P+DgaefDFd+DvGlHP29jld/v\nUrnNf/Ee2gXVu+HQHn/p+sUbSvLhkJjmv9DyZwRfDjMhf7rf+gS/xffOn30YlK/3t6XnQ8OBI1uA\n6Xn+n79gtv/i2r/WB0J7i78/nOK74EZN9V+uuZP99dxJ/gu6tenoLdnGKh8kqx7w65E6Eube5M+F\nyZ8BZRtg+T3+y6W1wXcLLrrN7/tJyfZzfncOqfJNvpW3+WkftBd+yZ+RH0qElga/0bHil34LN5Tk\nD26o3e//DpHgHBkLQc4Ef9Raw4Ge/76hZP/lOmYujJ0HY8/w72lPIbxvja9t6/P+i/SCL/gWcNbY\nnl+js+ZaqCsP3rfqTq2Cal97WpcWWKrvGeDAO1C+0Yd1+Ub/e1uTD9TTzvfjm02/6tgNmMptvit3\n09M+DFzEv2dj5vr3v+hMGLfoxPW3t/n3/dXv+RpyTvPPkZ7nLxnBz/R831uQWdC796MLhUI//eSF\nLfzHc++w5muXkp3aj62ceNfWfKTborEKmmt8eFiC/3KyBH+JtMG7L/vDX2v2+K3kaZf7f8Cdr8Ob\n/+m3pt7/I98q6izSDiW/gBe/5bvG5v2tv61yq780VB69fHq+f64R4/zghdlF/p+3tQFaG/1ztDZC\naz3U7PP/mDWlRx6fmO63jBsP+i/E8Wf7/TtTL4dRk/3j968L+opX+5/lG33AFMz2Q6gfvoyc1L+W\nSSQC21/2gy1ufMoPe5JT7LeOwyk+WBfd7r9MemPXm/Dc12D3m76m4nNh/R+g+ZAPqQW3+q7Bw1+E\nbS2+q6t8Q/DFucWHTnaR38LOLoSsIsga40Nk7yr/Xuxd7btOmg/550nKgMIzgi/NRX7Lv6kaXvw2\nrHvUt2je8/ngZNDUvr9PgyHS7tdzwx9g3WN+Kz4hDJOW+K7Sg9t9GFRs8ssXnA7Tr/AbOGPmQmJK\nP1834ruTSn7hP3915f696eycO/p99KFCoZ+Wbj3Azfcu4/6PL+KCqVE430COFon4L6a3H/VbS40H\n/e0LPwEXf/34/bz1B+D5r8Hq3/qt3tzJwaiyk/1l5CQYMb5//6SN1X4Lv2Kj37puOgST3uu77I7X\n5dWxXu1R6QIA/HqvechvUU+80LcaelNTV875Q5yf/7r/opt5jQ+DCecM7o7PSMR3aZWu9FvUu5f5\n7qnDh0Jbgm9VLP4/fij64XT4s3M+3NY97j+fh3b7DYMJ5/jWw7TLfaspWtpafGusvsLvaM8u9C3E\nflAo9FNdcxtzvv4M/7BkCp+9ZGrUXke60d4K2//qvxQKF/T+cdH8Ao4HkYhvuR3vaLTB1lwHe1f6\n7sDWBt/KyRw9dK/fH5GI7zbMKuxfCMdYb0NBRx91kZEcZmpBP2dik4EJJR7bVdQbCoSBSUiAhCEM\nBPD7j047319OFgkJvgvwFBf745+GoQUTcli9q7rvM7GJiJzkFArdOGN8DrXNbWwp78dMbCIiJ7Go\nhYKZjTOzl8xsg5mtN7M7u1nmQjM7ZGarg8tXo1VPX3Q+iU1EJJ5Es6XQBnzeOTcTWAx8xsxmdrPc\nq865ecHlm1Gsp9eKc9MYmZ7Eyp0KBRGJL1ELBefcPufcyuB6LbARGMLBcvrPzJg/bgAzsYmInKSG\nZJ+CmRUD84Fl3dx9tpmtMbM/m9msHh5/u5mVmFlJRUVFFCs94owJOWyrqKe6oWVIXk9EZDiIeiiY\nWQbwGHCXc66my90rgQnOubnAT4Dfd/cczrl7nHMLnXML8/KG5oSy+eP9CTSrdg9gfgURkZNMVEPB\nzBLxgfCAc+7xrvc752qcc3XB9T8BiWY2LMZGnls0ggSDFTvUhSQi8SOaRx8ZcB+w0Tn3/R6WGR0s\nh5ktCuqp7G7ZoZaeHObsSbk8umIPLW2RWJcjIjIkotlSOBf4MLCk0yGnV5jZp8zsU8Ey1wPrzGwN\n8GPgJjeMxt34u/dMZH9NE0+/vTfWpYiIDImoDXPhnHsNOO6oWs65nwI/jVYNA3Xh1Dym5Gdwz1+3\nc+28QmwYzY4kIhINOqP5OMyM294zkY37anh927Do1RIRiSqFwglcM38sozKSueev78a6FBGRqFMo\nnEByOMSt50zglXcq2Ly/NtbliIhElUKhF24+awKpiSHufVWtBRE5tSkUeiEnPYkbFxbx+9WllNc0\nxbocEZGoUSj00sfPO422iOOXr++IdSkiIlGjUOilCbnpXDZrNA8s20V9c1usyxERiQqFQh/cdv5E\nDjW28kjJ7liXIiISFQqFPjhjfA4LJuRw39LttGuqThE5BSkU+ui290xk98FGnlm/P9aliIgMOoVC\nH10ys4Di3DR+9PwWmlrbY12OiMigUij0USjB+Nr7Z7G5rJYv/34dw2j8PhGRAVMo9MN7p+dzx5LJ\nPLpiDw8u105nETl1KBT66c6Lp3L+1Dy+/uR61mh2NhE5RSgU+imUYPzog/PIy0zm0w+s5GC95nIW\nkZOfQmEActKT+K9bzqCitpk7H1qlw1RF5KSnUBigOUUj+MY1s3h1ywF+9Pw7sS5HRGRAFAqD4KYz\nx3HDgiJ+/OJWXtxUFutyRET6TaEwCMyMb107m1ljs7jrodXsrW6MdUkiIv2iUBgkKYkhfva3Z9AW\ncXzh0TVEtH9BRE5CCoVBVDwqna9cNZOlWys1xLaInJQUCoPspjPHcdH0fP71L5vYUqbpO0Xk5KJQ\nGGRmxr9eN4eM5DB3PbyalrZIrEsSEek1hUIU5GUm850PnM76vTX86AUdpioiJ4+ohYKZjTOzl8xs\ng5mtN7M7u1nGzOzHZrbVzNaa2RnRqmeovW/WaG5cWMR/vbyNkh0HY12OiEivRLOl0AZ83jk3E1gM\nfMbMZnZZ5nJgSnC5HfivKNYz5L76/lkU5qTyud+toU5TeIrISSBqoeCc2+ecWxlcrwU2AoVdFrsG\n+JXz3gRGmNmYaNU01DKSw3yh3W18AAARQUlEQVT/xnnsrmrgn5/aEOtyREROaEj2KZhZMTAfWNbl\nrkKg89jTezg2ODCz282sxMxKKioqolVmVJxZPJJPXTCJh97azeMr98S6HBGR44p6KJhZBvAYcJdz\nrqY/z+Gcu8c5t9A5tzAvL29wCxwCn714KmdPzOWfHlvLsncrY12OiEiPohoKZpaID4QHnHOPd7NI\nKTCu0+9FwW2nlKRwAv99ywLGj0zjk79ZwbsVdbEuSUSkW9E8+siA+4CNzrnv97DYk8BHgqOQFgOH\nnHP7olVTLGWnJfK/ty4iwYyP//Itzb8gIsNSNFsK5wIfBpaY2ergcoWZfcrMPhUs8yfgXWAr8HPg\n01GsJ+bG56bx848sYO+hJj756xKa29pjXZKIyFHsZJt4fuHCha6kpCTWZQzIk2v2cseDq7h23lh+\n8MF5+EaViEj0mNkK59zCEy0XHopi5GhXzx3Lrsp6vvfsO0zITeezl0yNdUkiIoBCIWY+897JbD/Q\nwI9e2MJf1u1nRFoiOWlJjEhLZERaEjlpibxv1miKR6XHulQRiSMKhRgxM77zgdMpyEpma3kd1Q2t\nbKuoo7qxleqGFlrbHb9Yup2n73gPozKSY12uiMQJhUIMJYUT+OJl04+53TnH26WHuP6/3+DOh1bx\nq4+fRShB+x1EJPo0SuowZGbMKRrBt66ZxdKtlfzohS2xLklE4oRCYRi7ceE4rl9QxE9e3MLLm8tj\nXY6IxAGFwjBmZnzrmtlMK8jksw+vprS6MdYlicgpTvsUhrnUpBD/efMZXP3TpXzmgZX87pNnkxQ+\nNsubWttZu+cQe6oaKK1qpLQ6uFQ1crChhfOn5HHjwnGcMymXhOPsn3DOsaOygfKapm7vTwwnMDIt\niZz0JLJSwoN+jkVtUyt7qhrJSA6TkRwmPTnc7frGi4aWNnZWNjC1ILPX+5Uq65rJSk0kMTS83zfn\nHNsP1LOnqpHi3HQKc1K172wYUCicBCbmZfBv18/h0w+s5F/+tJGvXz0LgAN1zby4qZznNpTx6pYK\nmlqPTP05KiOJwpw0ZozJIiUxxPMby3hyzV4KR6Ryw8Iirl9QRFFOWsfzLN16ILhU9rpFEkowctKS\nGJmeSEFWCu+ZMool0wuYlJfer7B4dv1+vvT428cMAZIUTiAjOczYESlcM7eQa+cXkpfZ8xFZ60oP\n8eDyXTy/sYwl0wv44vumkZOe1Od6OotE3HHDdDA55yjZWcWjJXt4+u191DW3MSItkfdOy2fJ9HzO\nn5pHdmpix/LNbe28tb2KV94p55V3KninrI7s1EQumzWaq+aO4eyJuYT7GBD7DzXxwqYyNuyt4fTC\nbBZPzGVCblq3f9fW9gglO6p4+Z1yXttygNTEELPGZjGrMJtZY7OYkp/ZEezlNU0s3eY/Z69vPcDe\nQ0c2PpLCCRTnpnHaqHQm5mUwJT+DsybmUjgitU/v3cH6FvYdagoujew71ERVfQuNre00trQf9TM1\nMcS18/1nKiM59l+HTa3trNxZRUZKmMIRqYxMTxryk1t1RvNJ5Jt/3MAvlm7nw4snsHFfDSt2VeEc\njM1O4ZKZBZw/NY/iUekUjkglJTF01GObWtt5bkMZvyvZzWtbDwCw+LRcqhtb2bjPD16bnZrIOZNy\nOXfyKE4blU53H8XmtghVDS0crG8JfrZysL6ZHQca2FxWC8CE3DQuml7ARTPyObN45Am39Oub2/jn\npzfw4PLdzByTxScvmEhzW4T65jbqm9uoDX6uK61h9e5qwgnGhdPyuWFhEUum55MYSqC2qZUn1+zl\noeW7ebv0EMnhBM6amMvSrQfITk3kS5dP5/ozivr0xV7T1Mof1+zlkZI9rN5dTUpiwlEtmPTkMJnJ\nYTJTwmSmJJKZEiYrNfiZksiojGRGZ6cwOiuF1KTQCV9vb3Ujj6/cw6Mr9rCjsoG0pBBXnj6GM08b\nyZvvVvLy5goO1rcQSjDOLM5hUfFI1u+t4fVtlTS2tpMUSmDRaSM5Z3IuW8rqeG5DGXXNbYxMT+Ky\n2aO5as4YFkzIITl8bC3OOTbuq+X5jWU8v7GMtXsOAZCaGKKx1Q/HUpCVzFmn5bJ4Yi5zirJZv/cQ\nL22qYOnWA9Q2txFOMBZMyKE94tiwr4aGFv+4pFACU0dn0NwaYUu5HwxyRJr/rJ0zaRST8jLYfbCB\nbRV1bKuo590DdeyqbKAt4r+bThuVznmTR3Hu5FGcPSm3IxCr6ltYv7eG9XsPsX5vDRv21bDrYMMx\n86InhvzGS1pSiJTEEKlJIdKSQqQmhthT1cim/bWkJYW4Zl4hN581ntmF2Uc9vqK2mWXbK3nz3UpK\ndlRR29RGa3uE9ojr+NkWccwam8Vn3juZJdPz+/RF3h5xvLGtkt+vLuWZdfup7TQhV0piAmNHpFI4\nIpWinFQunlHARTMKev3cnfX2jGaFwkmkpS3Ch37+Jit2VjFrbBaXzCzg4hkFzBqb1acP4Z6qBh5b\nUcpTa/cyKiOZ86aM4rzJo5hdmD2g5ntpdSMvbirnxY1lLN1WSUtbhMzkMBfNyOeK08dw/tS8Y8Jq\n1a4qPvvwanYebOBTF0zisxdPPW6IbC2v5ZEVe3h8ZSkVtc3kpiexsDiHV7ccoKGlnemjM/nQovFc\nO6+Q7LRENu2v4ctPrKNkZxULJ+TwrWtnM2NMVo/PH4k4Xt9WySMrdvOXdftpboswtSCDi2YU0B5x\n1Da1dYRVXXCpbWqjtqmVmqY22iPd/z9lpYQZnZ1CQVYKyeGEjq3VptYITa1+q3V/TRPOweKJI7l+\nwTgunz2a9E5br+0Rx+rdVbywsZwXN5WzaX8t40emceG0PC6YmsfZk3JJSzqyfFNrO6+8U8FTa/fx\nwsayji/pxJCRluTDLS0pRHpymIraZkqrGzGD+eNGcPHMAi6ZUcDk/Ay2VdQHX4oHefPdSipqmzte\nY3RWCu+dnscFU/M5d3IumSmJHe/j9sr6I1/apTWEEqxjo2PmmKzjBnRre4RtFXUs3VrJ0q0HePPd\nShpa2kkwmDk2i4N1LUe1MsZmpzBzbDaT8tIZnZ3CmOxUxo5IYXR2CqPSk3t8Lecca/Yc4rfLdvLk\nmr00tUaYW5TN++eOZfuBet58t5JtFfUApCeFWFA8kvzMZBJDRijBCCckEA6e+y/r97OnqpGZY7L4\nhyWTed+s0T2+biTiWLf3EH9YvZc/rtlLeW0zGclhLps9mstnj6Yt4tgbdP+WVjf669WN3LJ4Andd\n3L8REBQKp6jGlnZqm1rJz0qJdSnH1dDSxtKtlTy3YT/PbiijuqGVjOQwFwcBce7kUdz76nZ+/OIW\nRmel8P0b53LWxNxeP39be4S/bqngkZI9lOysYsm0fD501njmFmUfE5CRiOOxlXv4zp83caixlY+d\nU8yS6flUNbRS1dBCdUNLx/Vl7x6ktLqRrJQwV88byw0LxjGnm+fsjnOOxtZ2apvaONTYSkVtM/sP\nNbG/pomyGt+dUVbTRFu7IzXYUk1JTPBbr4khxo1M49p5hYzPTevVe1DX3EZ6UqhXtTW2tPPS5nK2\nH6jvFGrtNLT4YEtLCrFkej7vnZ5PfmbPn63D+wHeLj3EtNGZTCvIHJLujZa2CKt3V/Pa1gOU7DhI\nXmay76Iam83MMVkD7h4EONTYyhMr9/Db5bt4p6yOjOQwZxbnsHiibx3NGpt13G641vYIf1i9l/98\naSvvHqhnSn6GbznMyGdLWR0b99V0XDbtr6WhxbfuLpyWx7XzC1kyPf+YjaaunHP9fr8VCjJstLZH\neGNbJU+v3cczG/ZT3dBKKMFojzj+Zn4h37hmFlkpiSd+ogGqbmjhu3/ZzENv7aLrxz4tKUROWhKT\n8zO4bkERl84sOOE/qJyanHOUVjcyOiulz/tiwLfonn57Hz97cWtHl+phmSlhZozJYuaYLGYXZnPJ\njAKy06L/2QeFggxThwPipc3lLJwwkivnDP2U3FvKaqmoaw52kieRnZqoAJBBF4k4nt9YxjtltUwt\nyGTm2CwKR6TGbFRkhYKIiHTobSgM7wOZRURkSCkURESkg0JBREQ6KBRERKSDQkFERDooFEREpINC\nQUREOigURESkw0l38pqZVQA7+/nwUcCBQSznZBKv6671ji9a755NcM7lneiJTrpQGAgzK+nNGX2n\nonhdd613fNF6D5y6j0REpINCQUREOsRbKNwT6wJiKF7XXesdX7TeAxRX+xREROT44q2lICIix6FQ\nEBGRDnETCmZ2mZltNrOtZvalWNcTLWb2CzMrN7N1nW4baWbPmdmW4GdOLGuMBjMbZ2YvmdkGM1tv\nZncGt5/S625mKWa23MzWBOv9jeD208xsWfB5f9jMBj6J8TBkZiEzW2VmTwW/n/LrbWY7zOxtM1tt\nZiXBbYP2OY+LUDCzEPAz4HJgJvAhM5sZ26qi5pfAZV1u+xLwgnNuCvBC8Puppg34vHNuJrAY+Ezw\nNz7V170ZWOKcmwvMAy4zs8XAd4EfOOcmA1XAJ2JYYzTdCWzs9Hu8rPd7nXPzOp2bMGif87gIBWAR\nsNU5965zrgV4CLgmxjVFhXPur8DBLjdfA9wfXL8fuHZIixoCzrl9zrmVwfVa/BdFIaf4ujuvLvg1\nMbg4YAnwaHD7KbfeAGZWBFwJ3Bv8bsTBevdg0D7n8RIKhcDuTr/vCW6LFwXOuX3B9f1AQSyLiTYz\nKwbmA8uIg3UPulBWA+XAc8A2oNo51xYscqp+3n8IfBGIBL/nEh/r7YBnzWyFmd0e3DZon/PwQKuT\nk4tzzpnZKXscspllAI8BdznnavzGo3eqrrtzrh2YZ2YjgCeA6TEuKerM7Cqg3Dm3wswujHU9Q+w8\n51ypmeUDz5nZps53DvRzHi8thVJgXKffi4Lb4kWZmY0BCH6Wx7ieqDCzRHwgPOCcezy4OS7WHcA5\nVw28BJwNjDCzwxt9p+Ln/VzgajPbge8OXgL8iFN/vXHOlQY/y/EbAYsYxM95vITCW8CU4MiEJOAm\n4MkY1zSUngQ+Glz/KPCHGNYSFUF/8n3ARufc9zvddUqvu5nlBS0EzCwVuAS/P+Ul4PpgsVNuvZ1z\ndzvnipxzxfj/5xedczdziq+3maWbWebh68ClwDoG8XMeN2c0m9kV+D7IEPAL59y3Y1xSVJjZg8CF\n+KF0y4CvAb8HfgeMxw87fqNzruvO6JOamZ0HvAq8zZE+5v+L369wyq67mc3B71gM4Tfyfuec+6aZ\nTcRvQY8EVgG3OOeaY1dp9ATdR//onLvqVF/vYP2eCH4NA791zn3bzHIZpM953ISCiIicWLx0H4mI\nSC8oFEREpINCQUREOigURESkg0JBREQ6KBREhpCZXXh4RE+R4UihICIiHRQKIt0ws1uCeQpWm9n/\nBIPO1ZnZD4J5C14ws7xg2Xlm9qaZrTWzJw6PZW9mk83s+WCug5VmNil4+gwze9TMNpnZA9Z5gCaR\nGFMoiHRhZjOADwLnOufmAe3AzUA6UOKcmwW8gj9bHOBXwD855+bgz6g+fPsDwM+CuQ7OAQ6PYjkf\nuAs/t8dE/Dg+IsOCRkkVOdZFwALgrWAjPhU/wFgEeDhY5jfA42aWDYxwzr0S3H4/8EgwPk2hc+4J\nAOdcE0DwfMudc3uC31cDxcBr0V8tkRNTKIgcy4D7nXN3H3Wj2Ve6LNffMWI6j8XTjv4PZRhR95HI\nsV4Arg/Gqz88/+0E/P/L4RE4/xZ4zTl3CKgys/cEt38YeCWY/W2PmV0bPEeymaUN6VqI9IO2UES6\ncM5tMLMv42e3SgBagc8A9cCi4L5y/H4H8EMV/3fwpf8u8LHg9g8D/2Nm3wye44YhXA2RftEoqSK9\nZGZ1zrmMWNchEk3qPhIRkQ5qKYiISAe1FEREpINCQUREOigURESkg0JBREQ6KBRERKTD/weQ3LH/\n7MsNQQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq0KUOO68Zhe",
        "colab_type": "code",
        "outputId": "6dd7fbf9-696c-473d-91ff-6989640bf018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Evaluating the model\n",
        "test_result=[]\n",
        "q_est,r_est=[],[]\n",
        "with open(os.path.join(dataset_root,'real.json'),'r') as f_eval:\n",
        "  test_list=json.load(f_eval)\n",
        "\n",
        "for img in test_list:\n",
        "  img_path=os.path.join(dataset_root,'images','real',img['filename'])\n",
        "  img_arr=image.load_img(img_path,target_size=(299,299)) #This loads an image and resizes the image to (224, 224):\n",
        "  x=image.img_to_array(img_arr) #The img_to_array() function adds channels: x.shape = (224, 224, 3) for RGB and (224, 224, 1) for gray image\n",
        "  x=preprocess_input(x) #preprocess_input subtracts the mean RGB channels of the imagenet dataset. This is because the model you are using has been trained on a different dataset: x.shape is still (1, 224, 224, 3)\n",
        "  x=np.expand_dims(x,axis=0) #expand_dims() is used to add the number of images: x.shape = (1, 224, 224, 3)\n",
        "  output=model.predict(x)\n",
        "  output=output.tolist()\n",
        "  test_result.append({'filename':img['filename'],'q':output[:4],'r':output[4:]})\n",
        "  q_est.append(output[0][:4])\n",
        "  r_est.append(output[0][4:])\n",
        "  print(output)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.22132007777690887, 0.10470885783433914, 0.15069890022277832, -0.3384361267089844, 0.778200626373291, 0.781964898109436, 5.462565898895264]]\n",
            "[[0.2860822081565857, -0.15080243349075317, -0.030988097190856934, 0.029915502294898033, 0.3026317358016968, 0.42380762100219727, 4.1028618812561035]]\n",
            "[[0.004015312530100346, -0.5273644924163818, -0.19559383392333984, 0.36415570974349976, -0.25776687264442444, 0.5487515330314636, 6.530252933502197]]\n",
            "[[0.34322792291641235, 0.6643417477607727, -0.020405374467372894, 0.09958378225564957, -0.13867875933647156, 0.31973403692245483, 9.414289474487305]]\n",
            "[[-0.04545758664608002, -0.3558104634284973, 0.08025423437356949, 0.15308086574077606, -0.5026021003723145, 0.4410761892795563, 4.536001205444336]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIiK4fcvBPr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img_path=os.path.join(dataset_root,'images','test','img000014.jpg')\n",
        "# img_arr=image.load_img(img_path,target_size=(299,299))\n",
        "# x=image.img_to_array(img_arr)\n",
        "# x=preprocess_input(x)\n",
        "# x=np.expand_dims(x,axis=0)\n",
        "# output=model.predict(x)\n",
        "# output=output.tolist()\n",
        "# output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIM3gs2Sn4Zo",
        "colab_type": "text"
      },
      "source": [
        "**Extracting r_gt and q_gt from real.json**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ojs_fgUl6cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_json=[]\n",
        "q_gt,r_gt=[],[]\n",
        "with open(os.path.join(dataset_root,'real.json'),'r') as f:\n",
        "  real_json=json.load(f)\n",
        "for i in range(len(real_json)):\n",
        "  q_gt.append(real_json[i]['q_vbs2tango'])\n",
        "  r_gt.append(real_json[i]['r_Vo2To_vbs_true'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwJQ8wnhv-y-",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Orientation Score.**\n",
        "\n",
        "Orientation score is the angle of the rotation, that aligns the estimated and ground truth orientations:\n",
        "\n",
        "score(i)orientation=2arccos(q(i)est,q(i)gt)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMhDPt4loE0z",
        "colab_type": "code",
        "outputId": "d0bb574b-78d3-43d5-90ef-93399163150c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import math\n",
        "score_orientation=0\n",
        "bra_ket=[]\n",
        "for i in range(len(real_json)):\n",
        "  bra_ket.append(q_est[i][0]*q_gt[i][0]+q_est[i][1]*q_gt[i][1]+q_est[i][2]*q_gt[i][2]+q_est[i][3]*q_gt[i][3])\n",
        "  \n",
        "  \n",
        "for i in range(len(real_json)):\n",
        "  if bra_ket[i]<1:\n",
        "    score_orientation+=2*math.acos(bra_ket[i])\n",
        "score_orientation\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.895609107599252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1nAYXDswRCT",
        "colab_type": "text"
      },
      "source": [
        "**Calculating Position Score**\n",
        "\n",
        "The position score for image i is simply the 2-norm of the position error (difference of estimated and ground truth position vectors), normalized with the ground truth distance of the satellite:\n",
        "\n",
        "score(i)position=r(i)gtr(i)est2r(i)gt2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVgBqFY6wbRM",
        "colab_type": "code",
        "outputId": "16a49a85-256a-47e0-d095-b3eafec241f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from numpy import linalg\n",
        "score_position=0\n",
        "for i in range(len(real_json)):\n",
        "   score_position+=(abs(linalg.norm([r_gt[i]],2)-linalg.norm([r_est[i]],2))/linalg.norm([r_gt[i]],2))\n",
        "\n",
        "#linalg.norm([r_gt[0]])\n",
        "score_position"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8451222886828966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZO0fome1Hil",
        "colab_type": "text"
      },
      "source": [
        "**Finally, the total score is the average of pose scores over all images of the test set:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7Yo9gyh1JD6",
        "colab_type": "code",
        "outputId": "c20b64da-a453-4a7b-9560-994e70eb6c06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score=(score_orientation+score_position)/len(real_json)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.74814627925643"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}